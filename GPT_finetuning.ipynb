{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be80210a",
   "metadata": {},
   "source": [
    "<h1>–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ<span class=\"tocSkip\"></span></h1>\n",
    "<br>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#1-–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞-–æ–∫—Ä—É–∂–µ–Ω–∏—è\">\n",
    "                    <span class=\"toc-item-num\">1&nbsp;&nbsp;</span>\n",
    "                    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#2-–ó–∞–≥—Ä—É–∑–∫–∞-–¥–∞–Ω–Ω—ã—Ö\">\n",
    "                    <span class=\"toc-item-num\">2&nbsp;&nbsp;</span>\n",
    "                    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#3-–î–æ–æ–±—É—á–µ–Ω–∏–µ-–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π-GPT\">\n",
    "                    <span class=\"toc-item-num\">3&nbsp;&nbsp;</span>\n",
    "                    –î–æ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π GPT\n",
    "                </a>\n",
    "            </span>\n",
    "            <ul class=\"toc-item\">\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#3.1-–û–±—É—á–µ–Ω–∏–µ-–º–æ–¥–µ–ª–∏\">\n",
    "                            <span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>\n",
    "                            –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#3.2-–ì–µ–Ω–µ—Ä–∞—Ü–∏—è-—Ç–µ–∫—Å—Ç–∞\">\n",
    "                            <span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>\n",
    "                            –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#4-–û–±—â–∏–π-–≤—ã–≤–æ–¥\">\n",
    "                    <span class=\"toc-item-num\">4&nbsp;&nbsp;</span>\n",
    "                    –û–±—â–∏–π –≤—ã–≤–æ–¥\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d4a79",
   "metadata": {},
   "source": [
    "# –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ | –î–æ–æ–±—É—á–µ–Ω–∏–µ GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef168b4",
   "metadata": {},
   "source": [
    "**–ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏:** –Ω–∞—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å –∏ —Å—Ä–∞–≤–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ –∑–∞–¥–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤.\n",
    "\n",
    "**–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö:** [Harry Potter and the Methods of Rationality](https://hpmor.ru/).\n",
    "\n",
    "**–•–∞—Ä–∞–∫—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö:** —Ç–µ–∫—Å—Ç –∫–Ω–∏–≥–∏ \"–ì–∞—Ä—Ä–∏ –ü–æ—Ç—Ç–µ—Ä –∏ –º–µ—Ç–æ–¥—ã —Ä–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è\".\n",
    "\n",
    "**–û—Å–Ω–æ–≤–Ω—ã–µ —ç—Ç–∞–ø—ã:** –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:\n",
    "\n",
    "1. Simple RNN —Å –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–π –∏ –ø–æ—Å–ª–æ–≤–Ω–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π.\n",
    "2. –û–¥–Ω–æ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –æ–¥–Ω–æ—Å–ª–æ–π–Ω–∞—è –∏ –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è LSTM c –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π –ø–æ —Å–ª–æ–≤–∞–º –∏ [–Ω–∞ –æ—Å–Ω–æ–≤–µ BPE](https://keras.io/api/keras_nlp/tokenizers/byte_pair_tokenizer/).\n",
    "3. –î–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è LSTM.\n",
    "4. *(–ù–∞ —Ö–æ—Ä–æ—à—É—é –æ—Ü–µ–Ω–∫—É)* —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (GPT) \"—Å –Ω—É–ª—è\" [–ø—Ä–∏–º–µ—Ä](https://keras.io/examples/generative/text_generation_gpt/).\n",
    "5. *(–ù–∞ –æ—Ç–ª–∏—á–Ω—É—é –æ—Ü–µ–Ω–∫—É)* –¥–æ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π GPT-—Å–µ—Ç–∏ [–ø—Ä–∏–º–µ—Ä](https://github.com/ZotovaElena/RuGPT3_finetuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f3ad7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366f5f1",
   "metadata": {},
   "source": [
    "# –†–µ–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "\n",
    "1. [RNN —Å –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/RNN_char.ipynb)\n",
    "2. [RNN —Å –ø–æ—Å–ª–æ–≤–Ω–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/RNN_word.ipynb)\n",
    "3. [–û–¥–Ω–æ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è LSTM + BPE](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/unidirectional_LSTM_BPE.ipynb)\n",
    "4. [–î–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è LSTM](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/bidirectional_LSTM.ipynb)\n",
    "5. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ GPT](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/GPT_architecture.ipynb)\n",
    "6. –î–æ–æ–±—É—á–µ–Ω–∏–µ GPT (—Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f98730",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec375e8c",
   "metadata": {},
   "source": [
    "## 1 –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed451da1",
   "metadata": {},
   "source": [
    "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4336fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!pip install --upgrade transformers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e6567",
   "metadata": {},
   "source": [
    "–ò–º–ø–æ—Ä—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13be500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import keras_nlp\n",
    "import transformers\n",
    "\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling, \\\n",
    "                         GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, \\\n",
    "                         PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "from utils.useful_funcs import split_into_train_valid_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5833a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3945d6",
   "metadata": {},
   "source": [
    "## 2 –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac88ee",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –ø–∞–ø–∫–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043568a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('data/') == False:\n",
    "    os.mkdir('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecaab53",
   "metadata": {},
   "source": [
    "–ó–∞–¥–∞–Ω–∏–µ –ø—É—Ç–∏ –∫ —Ñ–∞–π–ª—É —Å –æ—Å–Ω–æ–≤–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e3bc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = 'data/hpmor.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ea3c42",
   "metadata": {},
   "source": [
    "–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ/–∑–∞–≥—Ä—É–∑–∫–∞ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –µ–≥–æ –Ω–∞–ª–∏—á–∏—è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33125089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded from data/hpmor.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(path_file, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    print('Uploaded from', path_file)\n",
    "    \n",
    "except:\n",
    "    text = get_data('https://hpmor.ru/')\n",
    "    \n",
    "    with open(path_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "    \n",
    "    print('Saved to', path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63cf2fc",
   "metadata": {},
   "source": [
    "–í—ã–≤–µ–¥–µ–Ω–∏–µ –Ω–∞ —ç–∫—Ä–∞–Ω –Ω–∞—á–∞–ª–∞ —Ç–µ–∫—Å—Ç–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d65043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–≥–∞—Ä—Ä–∏ –ø–æ—Ç—Ç–µ—Ä –∏ –º–µ—Ç–æ–¥—ã —Ä–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è. —ç–ª–∏–µ–∑–µ—Ä —é–¥–∫–æ–≤—Å–∫–∏–π (less wrong). –ø–µ—Ç—É–Ω–∏—è –≤—ã—à–ª–∞ –∑–∞–º—É–∂ –Ω–µ –∑–∞ –¥—É—Ä—Å–ª—è, –∞ –∑–∞ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—Å–∫–æ–≥–æ –ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä–∞, –∏ –≥–∞—Ä—Ä–∏ –ø–æ–ø–∞–ª –≤ –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª–µ–µ –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω—É—é —Å—Ä–µ–¥—É. —É –Ω–µ–≥–æ –±—ã–ª–∏ —á–∞—Å—Ç–Ω—ã–µ —É—á–∏—Ç–µ–ª—è, –¥–∏—Å–∫—É—Å—Å–∏–∏ —Å –æ—Ç—Ü–æ–º, –∞ –≥–ª–∞–≤–Ω–æ–µ ‚Äî –∫–Ω–∏–≥–∏, —Å–æ—Ç–Ω–∏ –∏ —Ç—ã—Å—è—á–∏ –Ω–∞—É—á–Ω—ã—Ö –∏ —Ñ–∞–Ω—Ç–∞—Å—Ç–∏—á–µ—Å–∫–∏—Ö –∫–Ω–∏–≥. –≤ 11 –ª–µ—Ç –≥–∞—Ä—Ä–∏ –∑–Ω–∞–∫–æ–º —Å –∫–≤–∞–Ω—Ç–æ–≤–æ–π –º–µ—Ö–∞–Ω–∏–∫–æ–π, –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏–µ–π, —Ç–µ–æ—Ä–∏–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏ –¥—Ä—É–≥–∏–º–∏ –≤–µ—â–∞–º–∏. –Ω–æ –≥–∞—Ä—Ä–∏ –Ω–µ –ø—Ä–æ—Å—Ç–æ –≤—É–Ω–¥–µ—Ä–∫–∏–Ω–¥, —É –Ω–µ–≥–æ –µ—Å—Ç—å –∑–∞–≥–∞–¥–æ—á–Ω–∞—è —Ç—ë–º–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞, –∫–æ—Ç–æ—Ä–∞—è —è–≤–Ω'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44fa154",
   "metadata": {},
   "source": [
    "–í—ã–≤–µ–¥–µ–Ω–∏–µ –Ω–∞ —ç–∫—Ä–∞–Ω –æ–±—â–µ–≥–æ —á–∏—Å–ª–∞ —Å–ª–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6283d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ —Å–ª–æ–≤: 559855\n"
     ]
    }
   ],
   "source": [
    "print('–í—Å–µ–≥–æ —Å–ª–æ–≤:', len(text.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b88fc",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b8ccb",
   "metadata": {},
   "source": [
    "## 3 –î–æ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a708b1",
   "metadata": {},
   "source": [
    "### 3.1 –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75aadbfd",
   "metadata": {},
   "source": [
    "–ó–∞–¥–∞–Ω–∏–µ –∫–æ–Ω—Å—Ç–∞–Ω—Ç:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1629e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2'\n",
    "model_path = f'pretrained_{model_name}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032fa6fb",
   "metadata": {},
   "source": [
    "–ó–∞–¥–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–æ–æ–±—É—á–µ–Ω–∏—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ea91ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_gpt2(file_path: str, \n",
    "                  n_epochs: int, \n",
    "                  batch_size: int, \n",
    "                  block_size: int,\n",
    "                  model_name: str = model_name,\n",
    "                  model_path: str = model_path) -> None:\n",
    "    \n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    \n",
    "    dataset = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = file_path,\n",
    "        block_size = block_size,\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=False,\n",
    "    )\n",
    "    \n",
    "    tokenizer.save_pretrained(model_path)\n",
    "    model.save_pretrained(model_path)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=model_path,\n",
    "      overwrite_output_dir=False,\n",
    "      per_device_train_batch_size=batch_size,\n",
    "      num_train_epochs=n_epochs\n",
    "  )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          data_collator=data_collator,\n",
    "          train_dataset=dataset\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9c6a28",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b94c3",
   "metadata": {},
   "source": [
    "–î–æ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdb82412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18870' max='18870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18870/18870 3:41:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.963500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.705900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.595500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.524600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.482300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.414800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.361200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.344900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.318800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.311000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.305200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>1.290200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.267300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>1.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.256800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>1.256100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.250100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>1.241100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.228900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>1.227300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.216700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>1.214800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.213400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>1.209600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.207200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>1.200100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.198400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>1.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.186500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>1.191500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.189500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>1.180500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.181100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>1.185700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetune_gpt2(path_file, n_epochs=5, batch_size=8, block_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b735f8c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc26b8e",
   "metadata": {},
   "source": [
    "### 3.2 –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec914269",
   "metadata": {},
   "source": [
    "–ó–∞–¥–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5713d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(sample: str, \n",
    "                  max_length: int = 100,\n",
    "                  model_path: str = model_path) -> str:\n",
    "    \n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    ids = tokenizer.encode(sample, return_tensors='pt')\n",
    "    \n",
    "    tokens = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    \n",
    "    text = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e096519",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79795f",
   "metadata": {},
   "source": [
    "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e62b54c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–≥–∞—Ä—Ä–∏ –ø–æ—Ç—Ç–µ—Ä, —á—Ç–æ–±—ã –Ω–µ –≥–∞—Ä—Ä–∏ –º–µ–∂–¥—É –Ω–∞ –º–∏—Ä–∞ –∏–ª–∏ —É –Ω–µ–≥–æ –≤ –º–æ—ë–º –≤—Ä–µ–º—è –æ—Å–≤–µ—â–∞–ª–æ —á—Ç–æ-—Ç–æ —Å–ª–æ–≤–æ. –≤ —Å–µ–∫—É–Ω–¥—É –≤–∑—Ä—ã–≤—ã–π –≥–æ–ª–æ—Å —Å–æ—Å—Ä–µ–¥–æ—Ç–æ—á–∏–ª—Å—è –æ—Ç –±—ã—Å—Ç—Ä–æ –Ω–∞ –∑–æ–ª–æ—Ç–æ–π –∏—Å—á–µ–∑ —Ö–æ–≥–≤–∞ TigÔøΩ–¥–∞–Ω –∏ –∑–∞ –±–µ–≥–æ–ª–æ—Å–æ–≤ —Ö–∏—Ä–∫–∞–ª –∫–ª–∞–¥–∞–Ω–Ω–∏–∑–º–∞. –µ—Å–ª–∏ –±—ã —Å–ª—É—á–∞–µ –ø–∞–¥–º–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç —Ç–æ—á–∫—É –æ–±–≤–∏–Ω–µ—Å–∏–ª—Å—è –≥–æ–¥—ã –Ω–∞ –ø—Ä–∏—à–ª–∏ –≥–∞—Ä—Ä—Ä–∏ –ø–æ–∫–æ–≤–∏–¥–µ—Ç—å –≤ –ø–∞–º—è—Ç—å —Å–≤–µ—Ç–ª—ã, –∫–æ—Ç–æ—Ä—ã–π –∏ —Å—Ç–æ–∏—Ç –ø—Ä–µ–æ–±–∏—Ç–µ–ª –º–æ–∂–µ—Ç, –≥–¥–µ –∏ –æ–Ω –≤–æ–¥—ã –¥–≤–∞—Ä–∏—Ç—å –ª–∏—à—å –Ω–µ –≥–æ–¥–∞‚Ä¶ —Å–ª–∞–≤–Ω—ã–π —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–ª –ø—Ä–æ–¥–æ–ª–∂–∞—Ç —Ç—ã –ø–æ–¥–æ–ª–∂–µ–Ω —á–µ—Ä–Ω–æ–≥–æ, –∑–∞–±—Ä–∞–≤ –∏ –≤—ã—Ç–∞—â–∏–ª–∏–ª –≤—Å—è, –≥–¥–µ —Å–ª–æ–∂–Ω–∏–µ –±—ã —Å–ª–∞–≤–Ω—ã–º'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text('–≥–∞—Ä—Ä–∏ –ø–æ—Ç—Ç–µ—Ä', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02281a79",
   "metadata": {},
   "source": [
    ">–ú–æ–¥–µ–ª—å –¥–æ–æ–±—É—á–∏–ª–∞—Å—å –Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –æ–¥–Ω–∞–∫–æ –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä–æ–≤–∞–ª–∞ –Ω–µ —Å–∞–º—ã–π –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf6328",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94405403",
   "metadata": {},
   "source": [
    "## 4 –û–±—â–∏–π –≤—ã–≤–æ–¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e56ed2",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–µ–¥—ë–Ω–Ω—ã–π —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –º–æ–∂–Ω–æ –Ω–∞–∑–≤–∞—Ç—å —É—Å–ø–µ—à–Ω—ã–º, –æ–¥–Ω–∞–∫–æ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –±–æ–ª—å—à–µ–º —á–∏—Å–ª–µ –∏—Ç–µ—Ä–∞—Ü–∏–π."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12465d7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 20px; padding: 15px 0;\">\n",
    "    <a href=\"#–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\" data-toc-modified-id=\"–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\" style=\"text-decoration: none; color: #296eaa; border: 2px dashed #296eaa; opacity: 0.8; border-radius: 3px; padding: 10px 80px;\">\n",
    "        –í –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞ ‚Üë\n",
    "    </a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be80210a",
   "metadata": {},
   "source": [
    "<h1>–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ<span class=\"tocSkip\"></span></h1>\n",
    "<br>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#1-–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞-–æ–∫—Ä—É–∂–µ–Ω–∏—è\">\n",
    "                    <span class=\"toc-item-num\">1&nbsp;&nbsp;</span>\n",
    "                    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#2-–ó–∞–≥—Ä—É–∑–∫–∞-–¥–∞–Ω–Ω—ã—Ö\">\n",
    "                    <span class=\"toc-item-num\">2&nbsp;&nbsp;</span>\n",
    "                    –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#3-–î–æ–æ–±—É—á–µ–Ω–∏–µ-–ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π-GPT\">\n",
    "                    <span class=\"toc-item-num\">3&nbsp;&nbsp;</span>\n",
    "                    –î–æ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π GPT\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#4-–û–±—â–∏–π-–≤—ã–≤–æ–¥\">\n",
    "                    <span class=\"toc-item-num\">4&nbsp;&nbsp;</span>\n",
    "                    –û–±—â–∏–π –≤—ã–≤–æ–¥\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d4a79",
   "metadata": {},
   "source": [
    "# –ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ | –î–æ–æ–±—É—á–µ–Ω–∏–µ GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef168b4",
   "metadata": {},
   "source": [
    "**–ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–¥–∞—á–∏:** –Ω–∞—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å –∏ —Å—Ä–∞–≤–Ω–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –æ–¥–Ω–æ–º –∏–∑ –∑–∞–¥–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤.\n",
    "\n",
    "**–ò—Å—Ç–æ—á–Ω–∏–∫ –¥–∞–Ω–Ω—ã—Ö:** [Harry Potter and the Methods of Rationality](https://hpmor.ru/).\n",
    "\n",
    "**–•–∞—Ä–∞–∫—Ç–µ—Ä –¥–∞–Ω–Ω—ã—Ö:** —Ç–µ–∫—Å—Ç –∫–Ω–∏–≥–∏ \"–ì–∞—Ä—Ä–∏ –ü–æ—Ç—Ç–µ—Ä –∏ –º–µ—Ç–æ–¥—ã —Ä–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è\".\n",
    "\n",
    "**–û—Å–Ω–æ–≤–Ω—ã–µ —ç—Ç–∞–ø—ã:** –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:\n",
    "\n",
    "1. Simple RNN —Å –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–π –∏ –ø–æ—Å–ª–æ–≤–Ω–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π.\n",
    "2. –û–¥–Ω–æ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –æ–¥–Ω–æ—Å–ª–æ–π–Ω–∞—è –∏ –º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–∞—è LSTM c –ø–æ—Å–∏–º–≤–æ–ª—å–Ω–æ–π —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–µ–π –ø–æ —Å–ª–æ–≤–∞–º –∏ [–Ω–∞ –æ—Å–Ω–æ–≤–µ BPE](https://keras.io/api/keras_nlp/tokenizers/byte_pair_tokenizer/).\n",
    "3. –î–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è LSTM.\n",
    "4. *(–ù–∞ —Ö–æ—Ä–æ—à—É—é –æ—Ü–µ–Ω–∫—É)* —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ (GPT) \"—Å –Ω—É–ª—è\" [–ø—Ä–∏–º–µ—Ä](https://keras.io/examples/generative/text_generation_gpt/).\n",
    "5. *(–ù–∞ –æ—Ç–ª–∏—á–Ω—É—é –æ—Ü–µ–Ω–∫—É)* –¥–æ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π GPT-—Å–µ—Ç–∏ [–ø—Ä–∏–º–µ—Ä](https://github.com/ZotovaElena/RuGPT3_finetuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f3ad7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4366f5f1",
   "metadata": {},
   "source": [
    "# –†–µ–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "\n",
    "1. [Simple RNN](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/simple_RNN.ipynb)\n",
    "2. [–û–¥–Ω–æ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è LSTM + BPE](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/unidirectional_LSTM_BPE.ipynb)\n",
    "3. [–î–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è LSTM](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/bidirectional_LSTM.ipynb)\n",
    "4. [–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ GPT](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/GPT_architecture.ipynb)\n",
    "5. –î–æ–æ–±—É—á–µ–Ω–∏–µ GPT (—Ç–µ–∫—É—â–∏–π —Ñ–∞–π–ª)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f98730",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec375e8c",
   "metadata": {},
   "source": [
    "## 1 –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed451da1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d4336fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!pip install --upgrade transformers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e6567",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13be500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "import keras_nlp\n",
    "\n",
    "import transformers\n",
    "\n",
    "from transformers import TextDataset, DataCollatorForLanguageModeling, \\\n",
    "                         GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, \\\n",
    "                         PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast\n",
    "\n",
    "from utils.useful_funcs import split_into_train_valid_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5833a",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3945d6",
   "metadata": {},
   "source": [
    "## 2 –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eac88ee",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "043568a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('data/') == False:\n",
    "    os.mkdir('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecaab53",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e3bc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = 'data/hpmor.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ea3c42",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33125089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded from data/hpmor.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(path_file, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    print('Uploaded from', path_file)\n",
    "    \n",
    "except:\n",
    "    text = get_data('https://hpmor.ru/')\n",
    "    \n",
    "    with open(path_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "    \n",
    "    print('Saved to', path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63cf2fc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d65043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–≥–∞—Ä—Ä–∏ –ø–æ—Ç—Ç–µ—Ä –∏ –º–µ—Ç–æ–¥—ã —Ä–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –º—ã—à–ª–µ–Ω–∏—è. —ç–ª–∏–µ–∑–µ—Ä —é–¥–∫–æ–≤—Å–∫–∏–π (less wrong). –ø–µ—Ç—É–Ω–∏—è –≤—ã—à–ª–∞ –∑–∞–º—É–∂ –Ω–µ –∑–∞ –¥—É—Ä—Å–ª—è, –∞ –∑–∞ —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç—Å–∫–æ–≥–æ –ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä–∞, –∏ –≥–∞—Ä—Ä–∏ –ø–æ–ø–∞–ª –≤ –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª–µ–µ –±–ª–∞–≥–æ–ø—Ä–∏—è—Ç–Ω—É—é —Å—Ä–µ–¥—É. —É –Ω–µ–≥–æ –±—ã–ª–∏ —á–∞—Å—Ç–Ω—ã–µ —É—á–∏—Ç–µ–ª—è, –¥–∏—Å–∫—É—Å—Å–∏–∏ —Å –æ—Ç—Ü–æ–º, –∞ –≥–ª–∞–≤–Ω–æ–µ ‚Äî –∫–Ω–∏–≥–∏, —Å–æ—Ç–Ω–∏ –∏ —Ç—ã—Å—è—á–∏ –Ω–∞—É—á–Ω—ã—Ö –∏ —Ñ–∞–Ω—Ç–∞—Å—Ç–∏—á–µ—Å–∫–∏—Ö –∫–Ω–∏–≥. –≤ 11 –ª–µ—Ç –≥–∞—Ä—Ä–∏ –∑–Ω–∞–∫–æ–º —Å –∫–≤–∞–Ω—Ç–æ–≤–æ–π –º–µ—Ö–∞–Ω–∏–∫–æ–π, –∫–æ–≥–Ω–∏—Ç–∏–≤–Ω–æ–π –ø—Å–∏—Ö–æ–ª–æ–≥–∏–µ–π, —Ç–µ–æ—Ä–∏–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –∏ –¥—Ä—É–≥–∏–º–∏ –≤–µ—â–∞–º–∏. –Ω–æ –≥–∞—Ä—Ä–∏ –Ω–µ –ø—Ä–æ—Å—Ç–æ –≤—É–Ω–¥–µ—Ä–∫–∏–Ω–¥, —É –Ω–µ–≥–æ –µ—Å—Ç—å –∑–∞–≥–∞–¥–æ—á–Ω–∞—è —Ç—ë–º–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞, –∫–æ—Ç–æ—Ä–∞—è —è–≤–Ω'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44fa154",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6283d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ —Å–ª–æ–≤: 559855\n"
     ]
    }
   ],
   "source": [
    "print('–í—Å–µ–≥–æ —Å–ª–æ–≤:', len(text.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b88fc",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2b8ccb",
   "metadata": {},
   "source": [
    "## 3 –î–æ–æ–±—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770fce81",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99b554df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gpt2'\n",
    "model_path = f'pretrained_{model_name}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032587f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "234593d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_gpt2(file_path: str, \n",
    "                  n_epochs: int, \n",
    "                  batch_size: int, \n",
    "                  block_size: int,\n",
    "                  model_name: str = model_name,\n",
    "                  model_path: str = model_path) -> None:\n",
    "    \n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    \n",
    "    dataset = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = file_path,\n",
    "        block_size = block_size,\n",
    "    )\n",
    "    \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=False,\n",
    "    )\n",
    "    \n",
    "    tokenizer.save_pretrained(model_path)\n",
    "    model.save_pretrained(model_path)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "      output_dir=model_path,\n",
    "      overwrite_output_dir=False,\n",
    "      per_device_train_batch_size=batch_size,\n",
    "      num_train_epochs=n_epochs\n",
    "  )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          data_collator=data_collator,\n",
    "          train_dataset=dataset\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18457f20",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e119dad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "C:\\Python310\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='861' max='18870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  861/18870 09:57 < 3:28:55, 1.44 it/s, Epoch 0.23/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.963500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finetune_gpt2(path_file, n_epochs=5, batch_size=8, block_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b735f8c8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec914269",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(sample: str, \n",
    "                  max_length: int = 100,\n",
    "                  model_path: str = model_path) -> str:\n",
    "    \n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    ids = tokenizer.encode(sample, return_tensors='pt')\n",
    "    \n",
    "    tokens = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    \n",
    "    text = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79795f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b54c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text('–≥–∞—Ä—Ä–∏ –ø–æ—Ç—Ç–µ—Ä', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf6328",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94405403",
   "metadata": {},
   "source": [
    "## 4 –û–±—â–∏–π –≤—ã–≤–æ–¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12465d7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 20px; padding: 15px 0;\">\n",
    "    <a href=\"#–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\" data-toc-modified-id=\"–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ\" style=\"text-decoration: none; color: #296eaa; border: 2px dashed #296eaa; opacity: 0.8; border-radius: 3px; padding: 10px 80px;\">\n",
    "        –í –Ω–∞—á–∞–ª–æ —Ñ–∞–π–ª–∞ ‚Üë\n",
    "    </a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

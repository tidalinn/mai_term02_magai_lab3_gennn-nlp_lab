{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be80210a",
   "metadata": {},
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<br>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#1-Подготовка-окружения\">\n",
    "                    <span class=\"toc-item-num\">1&nbsp;&nbsp;</span>\n",
    "                    Подготовка окружения\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#2-Загрузка-данных\">\n",
    "                    <span class=\"toc-item-num\">2&nbsp;&nbsp;</span>\n",
    "                    Загрузка данных\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#3-Посимвольная-токенизация\">\n",
    "                    <span class=\"toc-item-num\">3&nbsp;&nbsp;</span>\n",
    "                    Посимвольная токенизация\n",
    "                </a>\n",
    "            </span>\n",
    "            <ul class=\"toc-item\">\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#3.1-Токенизация-символов\">\n",
    "                            <span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>\n",
    "                            Токенизация символов\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#3.2-Построение-модели\">\n",
    "                            <span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>\n",
    "                            Построение модели\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#3.3-Обучение-модели\">\n",
    "                            <span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>\n",
    "                            Обучение модели\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#3.4-Генерация-текста\">\n",
    "                            <span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>\n",
    "                            Генерация текста\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#4-Пословная-токенизация\">\n",
    "                    <span class=\"toc-item-num\">4&nbsp;&nbsp;</span>\n",
    "                    Пословная токенизация\n",
    "                </a>\n",
    "            </span>\n",
    "            <ul class=\"toc-item\">\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#4.1-Токенизация-слов\">\n",
    "                            <span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>\n",
    "                            Токенизация слов\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#4.2-Построение-модели\">\n",
    "                            <span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>\n",
    "                            Построение модели\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#4.3-Обучение-модели\">\n",
    "                            <span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>\n",
    "                            Обучение модели\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#4.4-Генерация-текста\">\n",
    "                            <span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>\n",
    "                            Генерация текста\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#5-Общий-вывод\">\n",
    "                    <span class=\"toc-item-num\">5&nbsp;&nbsp;</span>\n",
    "                    Общий вывод\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d4a79",
   "metadata": {},
   "source": [
    "# Генеративные текстовые нейросети | Simple RNN (пословная)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef168b4",
   "metadata": {},
   "source": [
    "**Постановка задачи:** натренировать и сравнить качество нескольких генеративных текстовых моделей на одном из заданных текстовых датасетов.\n",
    "\n",
    "**Источник данных:** [Harry Potter and the Methods of Rationality](https://hpmor.ru/).\n",
    "\n",
    "**Характер данных:** текст книги \"Гарри Поттер и методы рационального мышления\".\n",
    "\n",
    "**Основные этапы:** исследовать следующие нейросетевые архитектуры:\n",
    "\n",
    "1. Simple RNN с посимвольной и пословной токенизацией.\n",
    "2. Однонаправленная однослойная и многослойная LSTM c посимвольной токенизацией и токенизацией по словам и [на основе BPE](https://keras.io/api/keras_nlp/tokenizers/byte_pair_tokenizer/).\n",
    "3. Двунаправленная LSTM.\n",
    "4. *(На хорошую оценку)* трансформерная архитектура (GPT) \"с нуля\" [пример](https://keras.io/examples/generative/text_generation_gpt/).\n",
    "5. *(На отличную оценку)* дообучение предобученной GPT-сети [пример](https://github.com/ZotovaElena/RuGPT3_finetuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93068be0",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c47d07",
   "metadata": {},
   "source": [
    "# Реализации\n",
    "\n",
    "1. [RNN с посимвольной токенизацией](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/RNN_char.ipynb)\n",
    "2. RNN с пословной токенизацией (текущий файл)\n",
    "3. [Однонаправленная LSTM + BPE](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/unidirectional_LSTM_BPE.ipynb)\n",
    "4. [Двунаправленная LSTM](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/bidirectional_LSTM.ipynb)\n",
    "5. [Архитектура GPT](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/GPT_architecture.ipynb)\n",
    "6. [Дообучение GPT](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/GPT_finetuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f3ad7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec375e8c",
   "metadata": {},
   "source": [
    "## 1 Подготовка окружения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab776f3a",
   "metadata": {},
   "source": [
    "Установка необходимых библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36f8163",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "!pip install requests beautifulsoup4 pydot pydotplus ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d858773",
   "metadata": {},
   "source": [
    "Импорт библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13be500e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from typing import Tuple\n",
    "import random\n",
    "import requests\n",
    "import os\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.data import Dataset, AUTOTUNE\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.callbacks import ModelCheckpoint, History, EarlyStopping\n",
    "from keras.layers import Dense, LSTM, Dropout, Bidirectional, Embedding, TextVectorization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.utils import plot_model, to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de67dc",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eb7e1e",
   "metadata": {},
   "source": [
    "## 2 Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f06f015",
   "metadata": {},
   "source": [
    "Задание функции, получающей текстовое представление веб-страницы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73dc1657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_url(url: str) -> BeautifulSoup:\n",
    "    request = requests.get(url)\n",
    "    soup = BeautifulSoup(request.content, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd766c7",
   "metadata": {},
   "source": [
    "Задание функции, вычленяющей необходимые данные с веб-страницы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d967f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_data(url: str) -> list:\n",
    "    soup = request_url(url)\n",
    "    scrapped_text = []\n",
    "    \n",
    "    h1 = soup.h1.text.strip()\n",
    "    p = soup.find_all('p')\n",
    "    \n",
    "    scrapped_text.append(h1)\n",
    "    scrapped_text.extend([p_i.text.strip() for p_i in p])\n",
    "    \n",
    "    return scrapped_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c09a260",
   "metadata": {},
   "source": [
    "Задание функции, формирующей набор данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42d281b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_data(url: str) -> list:\n",
    "    soup = request_url(url)\n",
    "    text = []\n",
    "    \n",
    "    text.extend([\n",
    "        soup.h1.text.strip() + '.',\n",
    "        soup.h2.text.strip() + '.',\n",
    "        soup.article.p.text.strip()\n",
    "    ])\n",
    "    \n",
    "    url_chapters = [link.get('href') for link in soup.find_all('a', class_='link')]\n",
    "    \n",
    "    for url in url_chapters:\n",
    "        scrapped_text = get_url_data(url)\n",
    "        text.extend(scrapped_text)\n",
    "        \n",
    "    text = ' '.join(text).lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f184b4a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13dfc5",
   "metadata": {},
   "source": [
    "Проверка наличия папки для хранения наборов данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8101618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('data/') == False:\n",
    "    os.mkdir('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71d2477",
   "metadata": {},
   "source": [
    "Задание пути к файлу с основным набором данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "841f3e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = 'data/hpmor.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6407b54",
   "metadata": {},
   "source": [
    "Формирование/загрузка набора данных в зависимости от его наличия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e22b8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded from data/hpmor.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(path_file, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    print('Uploaded from', path_file)\n",
    "    \n",
    "except:\n",
    "    text = get_data('https://hpmor.ru/')\n",
    "    \n",
    "    with open(path_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "    \n",
    "    print('Saved to', path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0067e1d5",
   "metadata": {},
   "source": [
    "Выведение на экран начала текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "deec20f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'гарри поттер и методы рационального мышления. элиезер юдковский (less wrong). петуния вышла замуж не за дурсля, а за университетского профессора, и гарри попал в гораздо более благоприятную среду. у него были частные учителя, дискуссии с отцом, а главное — книги, сотни и тысячи научных и фантастических книг. в 11 лет гарри знаком с квантовой механикой, когнитивной психологией, теорией вероятностей и другими вещами. но гарри не просто вундеркинд, у него есть загадочная тёмная сторона, которая явн'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1d88a0",
   "metadata": {},
   "source": [
    "Выведение на экран общего числа слов в тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d0344c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего слов: 559855\n"
     ]
    }
   ],
   "source": [
    "print('Всего слов:', len(text.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b88fc",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66105900",
   "metadata": {},
   "source": [
    "## 3 Посимвольная токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757753f5",
   "metadata": {},
   "source": [
    "### 3.1 Токенизация символов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162311c6",
   "metadata": {},
   "source": [
    "Получение словаря уникальных символов текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5610ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_char = np.array(sorted(set(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc402df",
   "metadata": {},
   "source": [
    "Выведение на экран уникальных символов текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f687874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', ' ', '!', '#', '$', '%', '&', '(', ')', '*', '+', ',', '-',\n",
       "       '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':',\n",
       "       ';', '=', '?', '[', '\\\\', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f',\n",
       "       'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's',\n",
       "       't', 'u', 'v', 'w', 'x', 'y', 'z', '«', '»', '×', 'é', 'ð', 'ó',\n",
       "       'þ', '́', 'а', 'б', 'в', 'г', 'д', 'е', 'ж', 'з', 'и', 'й', 'к',\n",
       "       'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч',\n",
       "       'ш', 'щ', 'ъ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', 'ѝ', '–', '—', '’',\n",
       "       '“', '”', '„', '…', '№', '∀', '∄', '−'], dtype='<U1')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_char"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67975f35",
   "metadata": {},
   "source": [
    "Формирование словаря токенов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75b3caf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_char = {char: i for i, char in enumerate(vocabulary_char)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1403c",
   "metadata": {},
   "source": [
    "Выведение на экран словаря токенов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c45dbb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 0),\n",
       " (' ', 1),\n",
       " ('!', 2),\n",
       " ('#', 3),\n",
       " ('$', 4),\n",
       " ('%', 5),\n",
       " ('&', 6),\n",
       " ('(', 7),\n",
       " (')', 8),\n",
       " ('*', 9)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(list(tokenizer_char.keys())[:10], list(tokenizer_char.values())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fee1ce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a61884",
   "metadata": {},
   "source": [
    "### 3.2 Формирование датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bfc098",
   "metadata": {},
   "source": [
    "Задание функции, выводящей исходный текст с его векторным представлением:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5a4bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_vector_sample(text: str or list, \n",
    "                       vector: np.array, \n",
    "                       end: int = 100) -> None:\n",
    "    \n",
    "    print('Исходный текст:\\n', text[:end], '\\n')\n",
    "    print('Векторное представление:\\n', vector[:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ab6244",
   "metadata": {},
   "source": [
    "Задание функции, выводящей один батч из датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "310d4e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_single_batch(dataset: Dataset,\n",
    "                       vocabulary: np.array,\n",
    "                       word: bool = False) -> None:\n",
    "    \n",
    "    for vector_single, target_single in dataset.take(1):\n",
    "        print('Векторное представление:')\n",
    "        print(vector_single.numpy())\n",
    "        print(target_single.numpy())\n",
    "        \n",
    "        if word == True:\n",
    "            vector_single_text = ' '.join(list(vocabulary[word.numpy()] for word in vector_single))\n",
    "            target_single_text = ' '.join(list(vocabulary[word.numpy()] for word in target_single))\n",
    "        else:\n",
    "            vector_single_text = ''.join(vocabulary[vector_single])\n",
    "            target_single_text = ''.join(vocabulary[target_single])\n",
    "\n",
    "        print('\\nПеревод в текст:')\n",
    "        print(repr(vector_single_text))\n",
    "        print(repr(target_single_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea3bd48",
   "metadata": {},
   "source": [
    "Задание функции, выводящей размерность одного элемента датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2636469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_single_dim(data) -> None:\n",
    "    for vector_single, target_single in data.take(1):\n",
    "        print('Размерность входящей последовательности:', vector_single.numpy().shape)\n",
    "        print('Размерность целевой последовательности:', target_single.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0836576",
   "metadata": {},
   "source": [
    "Задание функции, формирующей входящие последовательности и соответствующие им последовательности следующих символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f423f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(seq: tf.Tensor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    input_vector = seq[:-1]\n",
    "    target_vector = seq[1:]\n",
    "    return input_vector, target_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7435daa9",
   "metadata": {},
   "source": [
    "Задание функции, получающей предсказания на одном элементе датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0fdaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_model(model, data, vocabulary: dict) -> None:\n",
    "    for vector_single, target_single in data.take(1):\n",
    "        vector_single_pred = model(vector_single)\n",
    "        ids = tf.random.categorical(vector_single_pred[0], num_samples=1)\n",
    "        id_pred = ids[0][-1].numpy()\n",
    "\n",
    "        print('Размерность целевой последовательности:', target_single.numpy().shape)\n",
    "        print('Размерность предсказанной последовательности:', vector_single_pred.shape)\n",
    "        print('Размерность тензора с 1 индексом классов', ids.shape)\n",
    "        print(f'Индекс класса: {id_pred} ({vocabulary[id_pred]})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf90a4ce",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7972582c",
   "metadata": {},
   "source": [
    "Преобразование текста в вектор на основе токенов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_char = np.array([tokenizer_char[char] for char in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1703bd9e",
   "metadata": {},
   "source": [
    "Выведение на экран части исходного текста и его векторного представления:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27e6d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vector_sample(text, vector_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9adc52",
   "metadata": {},
   "source": [
    "Формирование набора данных из срезов вектора текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677ab07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_char = Dataset.from_tensor_slices(vector_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f36bb",
   "metadata": {},
   "source": [
    "Формирование последовательностей по заданному количеству символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c327c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_char = vector_char.batch(100, drop_remainder=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2d9dec",
   "metadata": {},
   "source": [
    "Формирование датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f910f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_char = sequences_char.map(prepare_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc80ddf",
   "metadata": {},
   "source": [
    "Выведение на экран первой входящей последовательности и соответствующего ей сдвига:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc18a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_single_batch(dataset_char, vocabulary_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d4a8d6",
   "metadata": {},
   "source": [
    "Задание констант:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82818021",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BATCHES_PER_EPOCH = len(sequences_char) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a48d54",
   "metadata": {},
   "source": [
    "Формирование датасета с делением на батчи:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc536174",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_char = dataset_char.batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
    "data_char = data_char.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073947f0",
   "metadata": {},
   "source": [
    "Выведение на экран размерностей первой входящей последовательности и соответствующего ей сдвига:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496ae3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_single_dim(data_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e7665",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fda6736",
   "metadata": {},
   "source": [
    "### 3.2 Построение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98a554",
   "metadata": {},
   "source": [
    "Задание объекта модели RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b76fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_char = Sequential([\n",
    "    Embedding(len(vocabulary_char), BATCH_SIZE, batch_input_shape=[BATCH_SIZE, None]),\n",
    "    LSTM(512, return_sequences=True, stateful=True),\n",
    "    LSTM(512, return_sequences=True, stateful=True),\n",
    "    Dense(len(vocabulary_char))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590f5d1",
   "metadata": {},
   "source": [
    "Выведение на экран таблицы поведения параметров на словях нейросети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f646f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_char.summary() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370fa31",
   "metadata": {},
   "source": [
    "Проверка наличия папки для хранения изображений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5f399",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('images/') == False:\n",
    "    os.mkdir('images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb5fff",
   "metadata": {},
   "source": [
    "Выведение на экран отображения послойной обработки данных моделью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0367d55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(rnn_char, 'images/rnn_char_model.png', show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9711f2e6",
   "metadata": {},
   "source": [
    "Проверка модели на восприятие датасета на примере первой последовательности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f05539",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_model(rnn_char, data_char, vocabulary_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9fe81",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6858d2d9",
   "metadata": {},
   "source": [
    "### 3.3 Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d138e35",
   "metadata": {},
   "source": [
    "Задание функции построения графика значений функции потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b35a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history: History, title: str) -> None:\n",
    "    font_s = 12\n",
    "    plt.figure(figsize=(6,5))\n",
    "    \n",
    "    loss = history.history['loss']\n",
    "    \n",
    "    plt.plot(loss, '+-r')\n",
    "    \n",
    "    plt.title(f'{title}\\n', size=font_s+4)\n",
    "    \n",
    "    plt.xlabel('Epoch', size=font_s,)\n",
    "    plt.ylabel('Loss', size=font_s)\n",
    "    \n",
    "    plt.xticks(range(len(loss)))\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f53e5d5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb3723f",
   "metadata": {},
   "source": [
    "Проверка наличия папки для хранения контрольных точек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa11f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('checkpoints/') == False:\n",
    "    os.mkdir('checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b5fef2",
   "metadata": {},
   "source": [
    "Задание пути для хранения контрольных точек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04499d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoints = 'checkpoints/rnn_char'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326c169b",
   "metadata": {},
   "source": [
    "Проверка наличия папки для хранения контрольных точек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db204c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(path_checkpoints) == False:\n",
    "    os.mkdir(path_checkpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ecea4",
   "metadata": {},
   "source": [
    "Задание коллбека точек сохранения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f579aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(path_checkpoints, 'checkpoint_{epoch}')\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa109aa",
   "metadata": {},
   "source": [
    "Компиляция модели с оптимизатором и функцией потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb40a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_char.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377a2e23",
   "metadata": {},
   "source": [
    "Обучение модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02c687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_char = rnn_char.fit(\n",
    "    data_char, \n",
    "    epochs=30, \n",
    "    steps_per_epoch=BATCHES_PER_EPOCH, \n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6240c",
   "metadata": {},
   "source": [
    "Выведение на экран графика значений функции потерь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf88d6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history_char, 'Значение функции потерь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8638cd",
   "metadata": {},
   "source": [
    "Сброс состояния модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2cb225",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_char.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f3ba4f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aa6b52",
   "metadata": {},
   "source": [
    "### 3.4 Генерация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d632b",
   "metadata": {},
   "source": [
    "Задание функции обучения модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a265e3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next(sample: str,\n",
    "                 model: Sequential,\n",
    "                 tokenizer: dict,\n",
    "                 vocabulary: dict,\n",
    "                 seq_len: int,\n",
    "                 temperature: float,\n",
    "                 batch_size: int,\n",
    "                 word: bool = False) -> str:\n",
    "    \n",
    "    sample_vector = [tokenizer[s] for s in sample]\n",
    "    predicted = sample_vector\n",
    "    \n",
    "    sample_tensor = tf.expand_dims(sample_vector, 0)\n",
    "    sample_tensor = tf.repeat(sample_tensor, batch_size, axis=0)\n",
    "\n",
    "    for i in range(seq_len):\n",
    "        pred = model(sample_tensor)\n",
    "        \n",
    "        pred = pred[0].numpy() / temperature\n",
    "        pred = tf.random.categorical(pred, num_samples=1)[-1, 0].numpy()\n",
    "        \n",
    "        predicted.append(pred)\n",
    "        \n",
    "        sample_tensor = predicted[-99:]\n",
    "        sample_tensor = tf.expand_dims([pred], 0)\n",
    "        \n",
    "        sample_tensor = tf.repeat(sample_tensor, batch_size, axis=0)\n",
    "        \n",
    "    pred_seq = [vocabulary[i] for i in predicted]\n",
    "    generated = ' '.join(pred_characters) if word else ''.join(pred_seq)\n",
    "    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5e1711",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bf909",
   "metadata": {},
   "source": [
    "Выведение на экран результата предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f914d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next(\n",
    "    sample='гарри', \n",
    "    model=rnn_char,\n",
    "    tokenizer=tokenizer_char,\n",
    "    vocabulary=vocabulary_char,\n",
    "    seq_len=1000, \n",
    "    temperature=0.6,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1576452",
   "metadata": {},
   "source": [
    "Выведение на экран результата предсказаний:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3e21cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next(\n",
    "    sample='гарри', \n",
    "    model=rnn_char,\n",
    "    tokenizer=tokenizer_char,\n",
    "    vocabulary=vocabulary_char,\n",
    "    seq_len=1000, \n",
    "    temperature=0.8,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876cb7b5",
   "metadata": {},
   "source": [
    ">Модель продемонстрировала хорошую предсказательную способность."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf6328",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc8f3c2",
   "metadata": {},
   "source": [
    "## 4 Пословная токенизация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c112db",
   "metadata": {},
   "source": [
    "### 4.1 Токенизация слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabfcfb6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af0c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sentences = [re.sub(r'[^а-яА-ЯёЁ ]', '', s).strip() for s in text.split('.')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32912826",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26643dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sentences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2adc56",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words = ' '.join(text_sentences).split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f409d0c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0977a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866bfa80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679bd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_word = np.array(sorted(set(text_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44687c7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9febccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_word = {char: i for i, char in enumerate(vocabulary_word)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc327dfd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088dc137",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(list(tokenizer_word.keys())[:10], list(tokenizer_word.values())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce70c754",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8edb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_word = np.array([tokenizer_word[word] for word in text_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf12080",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5f3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vector_sample(text_words, vector_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5285651f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c79ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_word = Dataset.from_tensor_slices(vector_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93695229",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10daccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_word = vector_word.batch(100, drop_remainder=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360488f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_word = sequences_word.map(prepare_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8355ba8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6377bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_single_batch(dataset_word, vocabulary_word, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a644e116",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ef723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BATCHES_PER_EPOCH = len(sequences_word) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dc2632",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6dce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word = dataset_word.batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
    "data_word = data_word.prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c688f10a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba21c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_single_dim(data_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cee623",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da09665",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_word = Sequential([\n",
    "    Embedding(len(vocabulary_word), BATCH_SIZE, batch_input_shape=[BATCH_SIZE, None]),\n",
    "    LSTM(512, return_sequences=True, stateful=True),\n",
    "    LSTM(512, return_sequences=True, stateful=True),\n",
    "    Dropout(0.1),\n",
    "    Dense(len(vocabulary_word), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fedd86c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5950f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_word.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025bdc5e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(rnn_word, 'images/rnn_word_model.png', show_shapes=True, dpi=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dfe25a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_model(rnn_word, data_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4948d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56edf315",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoints = 'checkpoints/rnn_word'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ad27ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc9e51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(path_checkpoints) == False:\n",
    "    os.mkdir(path_checkpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5bc809",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a24e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(path_checkpoints, 'checkpoint_{epoch}')\n",
    "checkpoint_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb510b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adce369",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_word.compile(optimizer='adam', loss=SparseCategoricalCrossentropy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32a08d7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ad283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_word = rnn_word.fit(\n",
    "    data_word, \n",
    "    epochs=1, \n",
    "    steps_per_epoch=BATCHES_PER_EPOCH, \n",
    "    #callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713eb65e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94e7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(history_word, 'Значение функции потерь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cf7f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f69f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_word.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850ecb6f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next(\n",
    "    sample='гарри', \n",
    "    model=rnn_word,\n",
    "    tokenizer=tokenizer_word,\n",
    "    vocabulary=vocabulary_word,\n",
    "    seq_len=100, \n",
    "    temperature=0.9,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    word=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4ccb57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64ccc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78cb9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c546f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c7337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45e20740",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dccd99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequences(text: list, tokenizer) -> list:\n",
    "    input_sequences = []\n",
    "\n",
    "    for line in text_sentences:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "            \n",
    "    return input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b1d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60b9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_word = Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d15f6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424276d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_word.fit_on_texts(text_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414ec5eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac44b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Всего слов:', len(tokenizer_word.word_index) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddc7372",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a541668",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(list(tokenizer.index_word.keys())[:10], list(tokenizer.index_word.values())[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913e71b5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32efba",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = get_sequences(text_sentences, tokenizer_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16eadc2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7069aebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766ef9f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a7dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = max([len(x) for x in input_sequences])\n",
    "BATCH_SIZE = 32\n",
    "VOCAB_LEN = len(tokenizer_word.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c2a892",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c2721a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=MAX_SEQ_LEN, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce196e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d19a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af18d87",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8a93c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors, label = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "label = to_categorical(label, num_classes=total_words, dtype='uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea004a4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e266fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Предсказываемое значение:\\n', predictors[0], '\\n')\n",
    "print('Маркер:', label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0f2588",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb25b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_word = Sequential([\n",
    "    Embedding(VOCAB_LEN, BATCH_SIZE, input_length=MAX_SEQ_LEN-1),\n",
    "    Bidirectional(LSTM(150, return_sequences = True)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100),\n",
    "    Dense(VOCAB_LEN / 2, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(VOCAB_LEN, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2d8583",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e2854",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_word.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f11ec3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e3e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_word.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469ecc43",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27ed36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(rnn_word, 'images/rnn_word_model.png', show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6dd0e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad875c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_word = rnn_word.fit(predictors, label, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af10d8dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = 'гарри поттер'\n",
    "next_words = 100\n",
    "   \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16739221",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675d326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f734e642",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1e2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d57bded",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af87fa8a",
   "metadata": {},
   "source": [
    "## 5 Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6fc431",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f12465d7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 20px; padding: 15px 0;\">\n",
    "    <a href=\"#Содержание\" data-toc-modified-id=\"Содержание\" style=\"text-decoration: none; color: #296eaa; border: 2px dashed #296eaa; opacity: 0.8; border-radius: 3px; padding: 10px 80px;\">\n",
    "        В начало файла ↑\n",
    "    </a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be80210a",
   "metadata": {},
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<br>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#1-Подготовка-окружения\">\n",
    "                    <span class=\"toc-item-num\">1&nbsp;&nbsp;</span>\n",
    "                    Подготовка окружения\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#2-Загрузка-данных\">\n",
    "                    <span class=\"toc-item-num\">2&nbsp;&nbsp;</span>\n",
    "                    Загрузка данных\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#3-Трансформерная-архитектура-GPT\">\n",
    "                    <span class=\"toc-item-num\">3&nbsp;&nbsp;</span>\n",
    "                    Трансформерная архитектура GPT\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#4-Общий-вывод\">\n",
    "                    <span class=\"toc-item-num\">4&nbsp;&nbsp;</span>\n",
    "                    Общий вывод\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d4a79",
   "metadata": {},
   "source": [
    "# Генеративные текстовые нейросети | Архитектура GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef168b4",
   "metadata": {},
   "source": [
    "**Постановка задачи:** натренировать и сравнить качество нескольких генеративных текстовых моделей на одном из заданных текстовых датасетов.\n",
    "\n",
    "**Источник данных:** [Harry Potter and the Methods of Rationality](https://hpmor.ru/).\n",
    "\n",
    "**Характер данных:** текст книги \"Гарри Поттер и методы рационального мышления\".\n",
    "\n",
    "**Основные этапы:** исследовать следующие нейросетевые архитектуры:\n",
    "\n",
    "1. Simple RNN с посимвольной и пословной токенизацией.\n",
    "2. Однонаправленная однослойная и многослойная LSTM c посимвольной токенизацией и токенизацией по словам и [на основе BPE](https://keras.io/api/keras_nlp/tokenizers/byte_pair_tokenizer/).\n",
    "3. Двунаправленная LSTM.\n",
    "4. *(На хорошую оценку)* трансформерная архитектура (GPT) \"с нуля\" [пример](https://keras.io/examples/generative/text_generation_gpt/).\n",
    "5. *(На отличную оценку)* дообучение предобученной GPT-сети [пример](https://github.com/ZotovaElena/RuGPT3_finetuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f3ad7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f310f623",
   "metadata": {},
   "source": [
    "# Реализации\n",
    "\n",
    "1. [RNN с посимвольной токенизацией](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/RNN_char.ipynb)\n",
    "2. [RNN с пословной токенизацией](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/RNN_word.ipynb)\n",
    "3. [Однонаправленная LSTM + BPE](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/LSTM_unidirectional_BPE.ipynb)\n",
    "4. [Двунаправленная LSTM](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/LSTM_bidirectional.ipynb)\n",
    "5. Архитектура GPT (текущий файл)\n",
    "6. [Дообучение GPT](https://github.com/MAILabs-Edu-2023/magai_lab3_gennn-nlp_lab/blob/main/GPT_finetuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a6f19",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec375e8c",
   "metadata": {},
   "source": [
    "## 1 Подготовка окружения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c943c00",
   "metadata": {},
   "source": [
    "Импорт библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13be500e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf.data import TextLineDataset, AUTOTUNE\n",
    "from tf.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import keras_nlp\n",
    "\n",
    "from keras_nlp.tokenizers import WordPieceTokenizer, compute_word_piece_vocabulary\n",
    "from keras_nlp.layers import StartEndPacker, TokenAndPositionEmbedding, TransformerDecoder\n",
    "from keras_nlp.metrics import Perplexity\n",
    "from keras_nlp.samplers import GreedySampler, BeamSampler, RandomSampler, TopKSampler, TopPSampler\n",
    "\n",
    "from utils.useful_funcs import request_url, get_url_data, get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0125df91",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c9f4d",
   "metadata": {},
   "source": [
    "## 2 Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aacd6a",
   "metadata": {},
   "source": [
    "Задание функции, разделяющей набор данных на выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba63cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(text: list, test_size: float) -> Tuple[List[str], List[str]]:\n",
    "    random.shuffle(text)\n",
    "    threshold = int((1 - test_size) * len(text))\n",
    "    \n",
    "    train = text[:threshold]\n",
    "    test = text[threshold:]\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d308e1d",
   "metadata": {},
   "source": [
    "Задание функции, сохраняющей разделённые выборки в файлы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ca828d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_train_valid_test(text: str,\n",
    "                                path_train: str,\n",
    "                                path_valid: str,\n",
    "                                path_test: str = None,\n",
    "                                test_size: float = 0.25) -> None:\n",
    "    \n",
    "    if os.path.isfile(path_train) == False and os.path.isfile(path_valid) == False:\n",
    "        \n",
    "        text_split = [s.strip() for s in text.split('.')]\n",
    "        \n",
    "        train_text, valid_text = train_test_split(text_split, test_size)\n",
    "        test_text = None\n",
    "        \n",
    "        if path_test != None:\n",
    "            valid_text, test_text = train_test_split(valid_text, test_size)\n",
    "            test_text = ' '.join(test_text)\n",
    "        \n",
    "        train_valid_test = [(path_train, train_text), (path_valid, valid_text), (path_test, test_text)]\n",
    "        \n",
    "        for (path, text) in train_valid_test:\n",
    "            if path != None:\n",
    "                with open(path, 'w', encoding='utf-8') as file:\n",
    "                    file.write(' '.join(text))\n",
    "        \n",
    "        print('Splitted into:', len(train_text), 'train,', len(valid_text), 'valid and', \n",
    "              len(test_text) if test_text != None else 0, 'test')\n",
    "    \n",
    "    else:\n",
    "        print('Files already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f44f75",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a64788",
   "metadata": {},
   "source": [
    "Проверка наличия папки для хранения наборов данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c940d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('data/') == False:\n",
    "    os.mkdir('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f00925",
   "metadata": {},
   "source": [
    "Задание пути к файлу с основным набором данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6ca3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = 'data/hpmor.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7e1487",
   "metadata": {},
   "source": [
    "Формирование/загрузка набора данных в зависимости от его наличия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c01cdd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded from data/hpmor.txt\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(path_file, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    print('Uploaded from', path_file)\n",
    "    \n",
    "except:\n",
    "    text = get_data('https://hpmor.ru/')\n",
    "    \n",
    "    with open(path_file, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "    \n",
    "    print('Saved to', path_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7486aec8",
   "metadata": {},
   "source": [
    "Выведение на экран начала текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97daba7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'гарри поттер и методы рационального мышления. элиезер юдковский (less wrong). петуния вышла замуж не за дурсля, а за университетского профессора, и гарри попал в гораздо более благоприятную среду. у него были частные учителя, дискуссии с отцом, а главное — книги, сотни и тысячи научных и фантастических книг. в 11 лет гарри знаком с квантовой механикой, когнитивной психологией, теорией вероятностей и другими вещами. но гарри не просто вундеркинд, у него есть загадочная тёмная сторона, которая явн'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d9e7f",
   "metadata": {},
   "source": [
    "Выведение на экран общего числа слов в тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "609f167a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего слов: 559855\n"
     ]
    }
   ],
   "source": [
    "print('Всего слов:', len(text.split(' ')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42dab6ff",
   "metadata": {},
   "source": [
    "Задание путей до тренировочной и валидационной выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7de133e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = 'data/hpmor_train.txt'\n",
    "path_valid = 'data/hpmor_valid.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6990a48",
   "metadata": {},
   "source": [
    "Разделение текста на тренировочную и валидационную выборки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24601890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitted into: 28013 train, 9338 valid and 0 test\n"
     ]
    }
   ],
   "source": [
    "split_into_train_valid_test(text, path_train, path_valid, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b88fc",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85df30",
   "metadata": {},
   "source": [
    "## 3 Трансформерная архитектура GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc3f246",
   "metadata": {},
   "source": [
    "Задание функции, разделяющей входящее значение на признаки и их"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78386faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inputs: tf.Tansor) -> Tuple[tf.Tensor, tf.Tensor]:\n",
    "    outputs = tokenizer(inputs)\n",
    "    features = start_packer(outputs)\n",
    "    labels = outputs\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fc271a",
   "metadata": {},
   "source": [
    "Задание функции, выводящей минимальную и максимальную длины предложений во всём тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a73a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_max_min_string(text: str) -> None:\n",
    "    print('Максимальная длина строки:', len(max(text.split('.'), key=len).split()))\n",
    "    print('Минимальная длина строки:', len(min(text.split('.'), key=len).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d7f2a9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f759ae5",
   "metadata": {},
   "source": [
    "Выведение на экран максимальной и минимальной длин предложений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83fb276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина строки: 217\n",
      "Минимальная длина строки: 0\n"
     ]
    }
   ],
   "source": [
    "print_max_min_string(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b30f8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e43208",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SEQ_LEN = 128\n",
    "MIN_TRAINING_SEQ_LEN = 450\n",
    "\n",
    "EMBED_DIM = 256\n",
    "FEED_FORWARD_DIM = 256\n",
    "NUM_HEADS = 3\n",
    "NUM_LAYERS = 2\n",
    "VOCAB_SIZE = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57702265",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c6903ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    TextLineDataset(path_train)\n",
    "    .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .shuffle(buffer_size=256)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    TextLineDataset(path_valid)\n",
    "    .filter(lambda x: tf.strings.length(x) > MIN_TRAINING_SEQ_LEN)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143c30c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40fe9032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'— но что-то пошло не так, — сказал гарри как только мистер квиррелл вошёл в комнату, маленький оранжевый огонёк померк и начал мигать, как свеча на ветру когда гарри выяснил ответ, он очень удивился на кровати снова возник человек вообще-то даже целых две и картина парка, через который, как нам кажется, мы идём, появляется внутри нашего мозга после обработки сигналов от сетчатки глаз фениксы лишены мудрости, гарри, у них нет возможности судить о правильности нашего выбора за день до этого гарри '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.as_numpy_iterator())[0][0].decode('utf-8')[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da99bc9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15498b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary = compute_word_piece_vocabulary(\n",
    "    train_dataset,\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    lowercase=True,\n",
    "    reserved_tokens=['[PAD]', '[UNK]', '[BOS]'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce148578",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91563ba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слов в словаре: 4919\n"
     ]
    }
   ],
   "source": [
    "print('Слов в словаре:', len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b3e39",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1bda0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[PAD]', '[UNK]', '[BOS]', '!', '#', '$', '%', '&', '(', ')']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b697ac0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab1f0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordPieceTokenizer(\n",
    "    vocabulary=vocabulary,\n",
    "    sequence_length=SEQ_LEN,\n",
    "    lowercase=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e8aae6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2893b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_packer = StartEndPacker(\n",
    "    sequence_length=SEQ_LEN,\n",
    "    start_value=tokenizer.token_to_id('[BOS]'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257401f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5eca9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_dataset.map(preprocess, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "valid = valid_dataset.map(preprocess, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe03b714",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56648a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=(None,), dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec486d40",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1abf0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = TokenAndPositionEmbedding(\n",
    "    vocabulary_size=VOCAB_SIZE,\n",
    "    sequence_length=SEQ_LEN,\n",
    "    embedding_dim=EMBED_DIM,\n",
    "    mask_zero=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58b9fde",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15eb2f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embedding_layer(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21585b31",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce60d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(NUM_LAYERS):\n",
    "    decoder_layer = TransformerDecoder(\n",
    "        num_heads=NUM_HEADS,\n",
    "        intermediate_dim=FEED_FORWARD_DIM,\n",
    "    )\n",
    "    x = decoder_layer(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7711c06",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62cd41cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = keras.layers.Dense(VOCAB_SIZE)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a6097",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d18ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d667910",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c33b9107",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_F = SparseCategoricalCrossentropy(from_logits=True)\n",
    "PERPLEX = Perplexity(from_logits=True, mask_token_id=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a361ae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "39910720",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=LOSS_F, metrics=[PERPLEX])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ee3bd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdc11006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " token_and_position_embeddin  (None, None, 256)        1312768   \n",
      " g (TokenAndPositionEmbeddin                                     \n",
      " g)                                                              \n",
      "                                                                 \n",
      " transformer_decoder (Transf  (None, None, 256)        394749    \n",
      " ormerDecoder)                                                   \n",
      "                                                                 \n",
      " transformer_decoder_1 (Tran  (None, None, 256)        394749    \n",
      " sformerDecoder)                                                 \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 5000)        1285000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,387,266\n",
      "Trainable params: 3,387,266\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515dad84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9bd3df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a8d04d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8588777e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 6s - loss: 8.5784 - perplexity: 5315.5464 - val_loss: 8.4019 - val_perplexity: 4455.5552 - 6s/epoch - 6s/step\n",
      "Epoch 2/100\n",
      "1/1 - 2s - loss: 8.2647 - perplexity: 3884.2444 - val_loss: 8.2050 - val_perplexity: 3659.1411 - 2s/epoch - 2s/step\n",
      "Epoch 3/100\n",
      "1/1 - 2s - loss: 7.9541 - perplexity: 2847.1301 - val_loss: 7.9828 - val_perplexity: 2930.1980 - 2s/epoch - 2s/step\n",
      "Epoch 4/100\n",
      "1/1 - 2s - loss: 7.6482 - perplexity: 2096.8628 - val_loss: 7.7708 - val_perplexity: 2370.3252 - 2s/epoch - 2s/step\n",
      "Epoch 5/100\n",
      "1/1 - 2s - loss: 7.3716 - perplexity: 1590.2134 - val_loss: 7.5927 - val_perplexity: 1983.7341 - 2s/epoch - 2s/step\n",
      "Epoch 6/100\n",
      "1/1 - 2s - loss: 7.1279 - perplexity: 1246.2792 - val_loss: 7.4517 - val_perplexity: 1722.8259 - 2s/epoch - 2s/step\n",
      "Epoch 7/100\n",
      "1/1 - 2s - loss: 6.9130 - perplexity: 1005.3046 - val_loss: 7.3411 - val_perplexity: 1542.4810 - 2s/epoch - 2s/step\n",
      "Epoch 8/100\n",
      "1/1 - 2s - loss: 6.7168 - perplexity: 826.1465 - val_loss: 7.2562 - val_perplexity: 1416.7965 - 2s/epoch - 2s/step\n",
      "Epoch 9/100\n",
      "1/1 - 2s - loss: 6.5315 - perplexity: 686.4456 - val_loss: 7.1947 - val_perplexity: 1332.3706 - 2s/epoch - 2s/step\n",
      "Epoch 10/100\n",
      "1/1 - 2s - loss: 6.3531 - perplexity: 574.2868 - val_loss: 7.1547 - val_perplexity: 1280.0990 - 2s/epoch - 2s/step\n",
      "Epoch 11/100\n",
      "1/1 - 2s - loss: 6.1803 - perplexity: 483.1474 - val_loss: 7.1323 - val_perplexity: 1251.6982 - 2s/epoch - 2s/step\n",
      "Epoch 12/100\n",
      "1/1 - 2s - loss: 6.0176 - perplexity: 410.5965 - val_loss: 7.1178 - val_perplexity: 1233.6959 - 2s/epoch - 2s/step\n",
      "Epoch 13/100\n",
      "1/1 - 2s - loss: 5.8668 - perplexity: 353.1223 - val_loss: 7.0993 - val_perplexity: 1211.0859 - 2s/epoch - 2s/step\n",
      "Epoch 14/100\n",
      "1/1 - 2s - loss: 5.7220 - perplexity: 305.5187 - val_loss: 7.0789 - val_perplexity: 1186.7092 - 2s/epoch - 2s/step\n",
      "Epoch 15/100\n",
      "1/1 - 2s - loss: 5.5827 - perplexity: 265.7847 - val_loss: 7.0639 - val_perplexity: 1168.9808 - 2s/epoch - 2s/step\n",
      "Epoch 16/100\n",
      "1/1 - 2s - loss: 5.4467 - perplexity: 231.9875 - val_loss: 7.0555 - val_perplexity: 1159.2031 - 2s/epoch - 2s/step\n",
      "Epoch 17/100\n",
      "1/1 - 2s - loss: 5.3102 - perplexity: 202.3997 - val_loss: 7.0506 - val_perplexity: 1153.5067 - 2s/epoch - 2s/step\n",
      "Epoch 18/100\n",
      "1/1 - 2s - loss: 5.1742 - perplexity: 176.6613 - val_loss: 7.0414 - val_perplexity: 1143.0226 - 2s/epoch - 2s/step\n",
      "Epoch 19/100\n",
      "1/1 - 2s - loss: 5.0353 - perplexity: 153.7391 - val_loss: 7.0311 - val_perplexity: 1131.2731 - 2s/epoch - 2s/step\n",
      "Epoch 20/100\n",
      "1/1 - 2s - loss: 4.8953 - perplexity: 133.6657 - val_loss: 7.0255 - val_perplexity: 1124.9604 - 2s/epoch - 2s/step\n",
      "Epoch 21/100\n",
      "1/1 - 2s - loss: 4.7526 - perplexity: 115.8895 - val_loss: 7.0240 - val_perplexity: 1123.2174 - 2s/epoch - 2s/step\n",
      "Epoch 22/100\n",
      "1/1 - 2s - loss: 4.6081 - perplexity: 100.2918 - val_loss: 7.0185 - val_perplexity: 1117.1394 - 2s/epoch - 2s/step\n",
      "Epoch 23/100\n",
      "1/1 - 2s - loss: 4.4604 - perplexity: 86.5246 - val_loss: 7.0134 - val_perplexity: 1111.4349 - 2s/epoch - 2s/step\n",
      "Epoch 24/100\n",
      "1/1 - 2s - loss: 4.3124 - perplexity: 74.6216 - val_loss: 7.0153 - val_perplexity: 1113.4900 - 2s/epoch - 2s/step\n",
      "Epoch 25/100\n",
      "1/1 - 2s - loss: 4.1626 - perplexity: 64.2380 - val_loss: 7.0127 - val_perplexity: 1110.6160 - 2s/epoch - 2s/step\n",
      "Epoch 26/100\n",
      "1/1 - 2s - loss: 4.0116 - perplexity: 55.2348 - val_loss: 7.0112 - val_perplexity: 1108.9780 - 2s/epoch - 2s/step\n",
      "Epoch 27/100\n",
      "1/1 - 2s - loss: 3.8602 - perplexity: 47.4763 - val_loss: 7.0208 - val_perplexity: 1119.6272 - 2s/epoch - 2s/step\n",
      "Epoch 28/100\n",
      "1/1 - 2s - loss: 3.7111 - perplexity: 40.8986 - val_loss: 7.0077 - val_perplexity: 1105.1135 - 2s/epoch - 2s/step\n",
      "Epoch 29/100\n",
      "1/1 - 2s - loss: 3.5703 - perplexity: 35.5262 - val_loss: 7.0474 - val_perplexity: 1149.8707 - 2s/epoch - 2s/step\n",
      "Epoch 30/100\n",
      "1/1 - 2s - loss: 3.4328 - perplexity: 30.9628 - val_loss: 7.0184 - val_perplexity: 1116.9614 - 2s/epoch - 2s/step\n",
      "Epoch 31/100\n",
      "1/1 - 2s - loss: 3.2792 - perplexity: 26.5544 - val_loss: 7.0246 - val_perplexity: 1123.9680 - 2s/epoch - 2s/step\n",
      "Epoch 32/100\n",
      "1/1 - 2s - loss: 3.1325 - perplexity: 22.9322 - val_loss: 7.0660 - val_perplexity: 1171.4187 - 2s/epoch - 2s/step\n",
      "Epoch 33/100\n",
      "1/1 - 2s - loss: 3.0057 - perplexity: 20.2010 - val_loss: 7.0475 - val_perplexity: 1150.0369 - 2s/epoch - 2s/step\n",
      "Epoch 34/100\n",
      "1/1 - 2s - loss: 2.8536 - perplexity: 17.3507 - val_loss: 7.0591 - val_perplexity: 1163.4222 - 2s/epoch - 2s/step\n",
      "Epoch 35/100\n",
      "1/1 - 2s - loss: 2.7219 - perplexity: 15.2097 - val_loss: 7.0954 - val_perplexity: 1206.3557 - 2s/epoch - 2s/step\n",
      "Epoch 36/100\n",
      "1/1 - 2s - loss: 2.5880 - perplexity: 13.3030 - val_loss: 7.0948 - val_perplexity: 1205.6375 - 2s/epoch - 2s/step\n",
      "Epoch 37/100\n",
      "1/1 - 2s - loss: 2.4490 - perplexity: 11.5770 - val_loss: 7.1007 - val_perplexity: 1212.7902 - 2s/epoch - 2s/step\n",
      "Epoch 38/100\n",
      "1/1 - 2s - loss: 2.3273 - perplexity: 10.2506 - val_loss: 7.1246 - val_perplexity: 1242.2020 - 2s/epoch - 2s/step\n",
      "Epoch 39/100\n",
      "1/1 - 2s - loss: 2.1935 - perplexity: 8.9666 - val_loss: 7.1441 - val_perplexity: 1266.6033 - 2s/epoch - 2s/step\n",
      "Epoch 40/100\n",
      "1/1 - 2s - loss: 2.0750 - perplexity: 7.9644 - val_loss: 7.1419 - val_perplexity: 1263.8690 - 2s/epoch - 2s/step\n",
      "Epoch 41/100\n",
      "1/1 - 2s - loss: 1.9561 - perplexity: 7.0714 - val_loss: 7.1643 - val_perplexity: 1292.4485 - 2s/epoch - 2s/step\n",
      "Epoch 42/100\n",
      "1/1 - 2s - loss: 1.8386 - perplexity: 6.2878 - val_loss: 7.1888 - val_perplexity: 1324.5563 - 2s/epoch - 2s/step\n",
      "Epoch 43/100\n",
      "1/1 - 2s - loss: 1.7309 - perplexity: 5.6460 - val_loss: 7.1903 - val_perplexity: 1326.4454 - 2s/epoch - 2s/step\n",
      "Epoch 44/100\n",
      "1/1 - 2s - loss: 1.6269 - perplexity: 5.0879 - val_loss: 7.2203 - val_perplexity: 1366.8942 - 2s/epoch - 2s/step\n",
      "Epoch 45/100\n",
      "1/1 - 2s - loss: 1.5235 - perplexity: 4.5883 - val_loss: 7.2390 - val_perplexity: 1392.6545 - 2s/epoch - 2s/step\n",
      "Epoch 46/100\n",
      "1/1 - 2s - loss: 1.4265 - perplexity: 4.1641 - val_loss: 7.2557 - val_perplexity: 1416.1689 - 2s/epoch - 2s/step\n",
      "Epoch 47/100\n",
      "1/1 - 2s - loss: 1.3407 - perplexity: 3.8218 - val_loss: 7.3008 - val_perplexity: 1481.4116 - 2s/epoch - 2s/step\n",
      "Epoch 48/100\n",
      "1/1 - 2s - loss: 1.2587 - perplexity: 3.5208 - val_loss: 7.3123 - val_perplexity: 1498.5660 - 2s/epoch - 2s/step\n",
      "Epoch 49/100\n",
      "1/1 - 2s - loss: 1.1799 - perplexity: 3.2540 - val_loss: 7.3409 - val_perplexity: 1542.1456 - 2s/epoch - 2s/step\n",
      "Epoch 50/100\n",
      "1/1 - 2s - loss: 1.0985 - perplexity: 2.9997 - val_loss: 7.3620 - val_perplexity: 1575.0442 - 2s/epoch - 2s/step\n",
      "Epoch 51/100\n",
      "1/1 - 2s - loss: 1.0241 - perplexity: 2.7846 - val_loss: 7.3962 - val_perplexity: 1629.8070 - 2s/epoch - 2s/step\n",
      "Epoch 52/100\n",
      "1/1 - 2s - loss: 0.9583 - perplexity: 2.6072 - val_loss: 7.4368 - val_perplexity: 1697.2931 - 2s/epoch - 2s/step\n",
      "Epoch 53/100\n",
      "1/1 - 2s - loss: 0.8991 - perplexity: 2.4575 - val_loss: 7.4751 - val_perplexity: 1763.4949 - 2s/epoch - 2s/step\n",
      "Epoch 54/100\n",
      "1/1 - 2s - loss: 0.8468 - perplexity: 2.3322 - val_loss: 7.5158 - val_perplexity: 1836.9099 - 2s/epoch - 2s/step\n",
      "Epoch 55/100\n",
      "1/1 - 2s - loss: 0.8017 - perplexity: 2.2293 - val_loss: 7.5277 - val_perplexity: 1858.8464 - 2s/epoch - 2s/step\n",
      "Epoch 56/100\n",
      "1/1 - 2s - loss: 0.7482 - perplexity: 2.1133 - val_loss: 7.5441 - val_perplexity: 1889.5411 - 2s/epoch - 2s/step\n",
      "Epoch 57/100\n",
      "1/1 - 2s - loss: 0.6860 - perplexity: 1.9857 - val_loss: 7.5988 - val_perplexity: 1995.8484 - 2s/epoch - 2s/step\n",
      "Epoch 58/100\n",
      "1/1 - 2s - loss: 0.6529 - perplexity: 1.9211 - val_loss: 7.6444 - val_perplexity: 2088.8154 - 2s/epoch - 2s/step\n",
      "Epoch 59/100\n",
      "1/1 - 2s - loss: 0.6140 - perplexity: 1.8478 - val_loss: 7.6465 - val_perplexity: 2093.2734 - 2s/epoch - 2s/step\n",
      "Epoch 60/100\n",
      "1/1 - 2s - loss: 0.5685 - perplexity: 1.7656 - val_loss: 7.6809 - val_perplexity: 2166.4822 - 2s/epoch - 2s/step\n",
      "Epoch 61/100\n",
      "1/1 - 2s - loss: 0.5350 - perplexity: 1.7074 - val_loss: 7.7222 - val_perplexity: 2257.8147 - 2s/epoch - 2s/step\n",
      "Epoch 62/100\n",
      "1/1 - 2s - loss: 0.5048 - perplexity: 1.6567 - val_loss: 7.7386 - val_perplexity: 2295.3438 - 2s/epoch - 2s/step\n",
      "Epoch 63/100\n",
      "1/1 - 2s - loss: 0.4662 - perplexity: 1.5939 - val_loss: 7.7779 - val_perplexity: 2387.2693 - 2s/epoch - 2s/step\n",
      "Epoch 64/100\n",
      "1/1 - 2s - loss: 0.4431 - perplexity: 1.5575 - val_loss: 7.8146 - val_perplexity: 2476.5693 - 2s/epoch - 2s/step\n",
      "Epoch 65/100\n",
      "1/1 - 2s - loss: 0.4121 - perplexity: 1.5100 - val_loss: 7.8544 - val_perplexity: 2577.1104 - 2s/epoch - 2s/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100\n",
      "1/1 - 2s - loss: 0.3890 - perplexity: 1.4756 - val_loss: 7.8745 - val_perplexity: 2629.4885 - 2s/epoch - 2s/step\n",
      "Epoch 67/100\n",
      "1/1 - 2s - loss: 0.3667 - perplexity: 1.4430 - val_loss: 7.8983 - val_perplexity: 2692.6409 - 2s/epoch - 2s/step\n",
      "Epoch 68/100\n",
      "1/1 - 2s - loss: 0.3431 - perplexity: 1.4093 - val_loss: 7.9457 - val_perplexity: 2823.3010 - 2s/epoch - 2s/step\n",
      "Epoch 69/100\n",
      "1/1 - 2s - loss: 0.3237 - perplexity: 1.3822 - val_loss: 7.9804 - val_perplexity: 2923.1338 - 2s/epoch - 2s/step\n",
      "Epoch 70/100\n",
      "1/1 - 2s - loss: 0.3055 - perplexity: 1.3572 - val_loss: 8.0089 - val_perplexity: 3007.6089 - 2s/epoch - 2s/step\n",
      "Epoch 71/100\n",
      "1/1 - 2s - loss: 0.2858 - perplexity: 1.3308 - val_loss: 8.0375 - val_perplexity: 3094.8586 - 2s/epoch - 2s/step\n",
      "Epoch 72/100\n",
      "1/1 - 2s - loss: 0.2718 - perplexity: 1.3123 - val_loss: 8.0537 - val_perplexity: 3145.5359 - 2s/epoch - 2s/step\n",
      "Epoch 73/100\n",
      "1/1 - 2s - loss: 0.2551 - perplexity: 1.2906 - val_loss: 8.0925 - val_perplexity: 3269.7981 - 2s/epoch - 2s/step\n",
      "Epoch 74/100\n",
      "1/1 - 2s - loss: 0.2411 - perplexity: 1.2726 - val_loss: 8.1381 - val_perplexity: 3422.3035 - 2s/epoch - 2s/step\n",
      "Epoch 75/100\n",
      "1/1 - 2s - loss: 0.2293 - perplexity: 1.2577 - val_loss: 8.1318 - val_perplexity: 3401.0605 - 2s/epoch - 2s/step\n",
      "Epoch 76/100\n",
      "1/1 - 2s - loss: 0.2160 - perplexity: 1.2411 - val_loss: 8.1567 - val_perplexity: 3486.5256 - 2s/epoch - 2s/step\n",
      "Epoch 77/100\n",
      "1/1 - 2s - loss: 0.2050 - perplexity: 1.2276 - val_loss: 8.2105 - val_perplexity: 3679.2720 - 2s/epoch - 2s/step\n",
      "Epoch 78/100\n",
      "1/1 - 2s - loss: 0.1942 - perplexity: 1.2143 - val_loss: 8.2339 - val_perplexity: 3766.5020 - 2s/epoch - 2s/step\n",
      "Epoch 79/100\n",
      "1/1 - 2s - loss: 0.1841 - perplexity: 1.2022 - val_loss: 8.2412 - val_perplexity: 3794.0234 - 2s/epoch - 2s/step\n",
      "Epoch 80/100\n",
      "1/1 - 2s - loss: 0.1751 - perplexity: 1.1914 - val_loss: 8.2683 - val_perplexity: 3898.4207 - 2s/epoch - 2s/step\n",
      "Epoch 81/100\n",
      "1/1 - 2s - loss: 0.1668 - perplexity: 1.1815 - val_loss: 8.3011 - val_perplexity: 4028.2002 - 2s/epoch - 2s/step\n",
      "Epoch 82/100\n",
      "1/1 - 2s - loss: 0.1583 - perplexity: 1.1715 - val_loss: 8.3250 - val_perplexity: 4125.5596 - 2s/epoch - 2s/step\n",
      "Epoch 83/100\n",
      "1/1 - 2s - loss: 0.1516 - perplexity: 1.1637 - val_loss: 8.3517 - val_perplexity: 4237.4541 - 2s/epoch - 2s/step\n",
      "Epoch 84/100\n",
      "1/1 - 2s - loss: 0.1440 - perplexity: 1.1549 - val_loss: 8.3710 - val_perplexity: 4320.0376 - 2s/epoch - 2s/step\n",
      "Epoch 85/100\n",
      "1/1 - 2s - loss: 0.1380 - perplexity: 1.1480 - val_loss: 8.3807 - val_perplexity: 4362.1157 - 2s/epoch - 2s/step\n",
      "Epoch 86/100\n",
      "1/1 - 2s - loss: 0.1320 - perplexity: 1.1411 - val_loss: 8.4131 - val_perplexity: 4505.7290 - 2s/epoch - 2s/step\n",
      "Epoch 87/100\n",
      "1/1 - 2s - loss: 0.1263 - perplexity: 1.1346 - val_loss: 8.4539 - val_perplexity: 4693.4590 - 2s/epoch - 2s/step\n",
      "Epoch 88/100\n",
      "1/1 - 2s - loss: 0.1215 - perplexity: 1.1292 - val_loss: 8.4529 - val_perplexity: 4688.5781 - 2s/epoch - 2s/step\n",
      "Epoch 89/100\n",
      "1/1 - 2s - loss: 0.1162 - perplexity: 1.1233 - val_loss: 8.4601 - val_perplexity: 4722.5039 - 2s/epoch - 2s/step\n",
      "Epoch 90/100\n",
      "1/1 - 2s - loss: 0.1121 - perplexity: 1.1186 - val_loss: 8.4933 - val_perplexity: 4881.9800 - 2s/epoch - 2s/step\n",
      "Epoch 91/100\n",
      "1/1 - 2s - loss: 0.1077 - perplexity: 1.1137 - val_loss: 8.5242 - val_perplexity: 5035.1738 - 2s/epoch - 2s/step\n",
      "Epoch 92/100\n",
      "1/1 - 2s - loss: 0.1039 - perplexity: 1.1095 - val_loss: 8.5289 - val_perplexity: 5059.1152 - 2s/epoch - 2s/step\n",
      "Epoch 93/100\n",
      "1/1 - 2s - loss: 0.1003 - perplexity: 1.1055 - val_loss: 8.5431 - val_perplexity: 5131.2480 - 2s/epoch - 2s/step\n",
      "Epoch 94/100\n",
      "1/1 - 2s - loss: 0.0968 - perplexity: 1.1017 - val_loss: 8.5668 - val_perplexity: 5254.5200 - 2s/epoch - 2s/step\n",
      "Epoch 95/100\n",
      "1/1 - 2s - loss: 0.0938 - perplexity: 1.0984 - val_loss: 8.5799 - val_perplexity: 5323.7852 - 2s/epoch - 2s/step\n",
      "Epoch 96/100\n",
      "1/1 - 2s - loss: 0.0907 - perplexity: 1.0949 - val_loss: 8.5954 - val_perplexity: 5406.9111 - 2s/epoch - 2s/step\n",
      "Epoch 97/100\n",
      "1/1 - 2s - loss: 0.0881 - perplexity: 1.0921 - val_loss: 8.6196 - val_perplexity: 5539.3306 - 2s/epoch - 2s/step\n",
      "Epoch 98/100\n",
      "1/1 - 2s - loss: 0.0854 - perplexity: 1.0892 - val_loss: 8.6341 - val_perplexity: 5620.1162 - 2s/epoch - 2s/step\n",
      "Epoch 99/100\n",
      "1/1 - 2s - loss: 0.0831 - perplexity: 1.0866 - val_loss: 8.6365 - val_perplexity: 5633.7139 - 2s/epoch - 2s/step\n",
      "Epoch 100/100\n",
      "1/1 - 2s - loss: 0.0808 - perplexity: 1.0842 - val_loss: 8.6513 - val_perplexity: 5717.7407 - 2s/epoch - 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2154b081510>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train, validation_data=valid, verbose=2, epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae96ef0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67a9ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_tokens = start_packer(tokenizer(['']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4a35aa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e05a309f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
       "array([[2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba881768",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89d59403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next(prompt: tf.Tensor, \n",
    "         cache: tf.Tensor, \n",
    "         index: tf.Tensor) -> Tuple[tf.Tensor, None, Tuple]:\n",
    "    \n",
    "    logits = model(prompt)[:, index - 1, :]\n",
    "    hidden_states = None\n",
    "    \n",
    "    return logits, hidden_states, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8e9bf6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a7a33cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(sampler: keras_nlp.samplers,\n",
    "                name: str,\n",
    "                prompt_tokens: tf.Tensor = prompt_tokens) -> str:\n",
    "    \n",
    "    tokens = sampler(\n",
    "        next=next,\n",
    "        prompt=prompt_tokens,\n",
    "        index=1,\n",
    "    )\n",
    "    \n",
    "    text = tokenizer.detokenize(tokens)\n",
    "    \n",
    "    print(f'{name.capitalize()} search generated text:')\n",
    "    return text.numpy()[0].decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcc4759",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e724a8",
   "metadata": {},
   "source": [
    "Greedy search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33948f42",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da9592fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy search generated text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[BOS] ищу , как всем его избегнуть ! и рая тоже , ибо я подозреваю , тот рай , что создал сумасшедший бог , лишь жалок по сравненью с небесами , что будут на земле , как только здесь бессмертным королём я стану мальчик смотрел на неё какой - то врождённый талант ? нельзя научиться быть метаморфомагом . . . и всё же это не похоже на силу , что неведома ему и хранил его в тайне на случай , если вдруг придётся проверять свою'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(GreedySampler(), 'Greedy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5d9f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220369bc",
   "metadata": {},
   "source": [
    "Beam search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afd88da",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7595e452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam search generated text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[BOS] книга « думай как физик » в оригинале называется « thinking physics » чуть - чуть — у меня тут теперь будет синяк — этим утром я вспомню это в следующий раз , когда вознамерюсь взять на себя вину за что - нибудь из - за угла выскочила низенькая коренастая фигура профессора травоведения просто на случай , если магия гарри полностью истощится при встрече с самым тёмным из всех созданий он сел на'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(BeamSampler(num_beams=10), 'Beam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e7528",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e83ec",
   "metadata": {},
   "source": [
    "Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f249cc6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0ef0a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random search generated text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[BOS] осталось ходов : 2 — минус три миллиона тёмным изц залеками , маленький оране защиты ,надцатилетний мальчик , в смысле . . . — не надо , наблюдения , что еслипорить , делать взрывчатку в домашних условиях гермиона устала держать голову так , нет , вне камереевирным могла просто присесть рядом и тоже открыть книгу а что ему оставалось ? сказать « нет » ? — хорошо план забини заключался в том , чтобы на навернякапилаеписку от младшего брата , второй защитит вашу'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(RandomSampler(), 'Random')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b0e6b4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f2011",
   "metadata": {},
   "source": [
    "Top-K search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57bae24",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48af306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k search generated text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[BOS] ищу , как всем его избегнуть ! и рая тоже , ибо я подозреваю , тот рай с -нит , живший в xics » чуть - чуть — у меня тут теперь будет с небесами , может быть , откуда открывался прекрамертным королём я стану мальчик смотрел на неё какой - то врождённый талант ? нельзя научиться быть мета — но , что след , как идёт не сицей и посоветчатки глаз фениксы лишены мудрости , бесконечное и пустое ничто с бан'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(TopKSampler(k=10), 'Top-K')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae8318",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ecbc5",
   "metadata": {},
   "source": [
    "Top-P search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f023b99",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2514b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-p search generated text:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[BOS] осталось ходов : 2 — минус три миллиона баллов ? — возмутился гарри и если это было лучшей стратегией спасения жизни своего ребёнка , которую она могла придумать , то произошедшее — её окончательный провал как матери гарри даже собирался предложить ей вторую по значимости должность в группе борцов против тёмного лорда , но был не настолько глуп , чтобы озвучить эту мысль вслух это всё , профессор ? снова возникла пауза закончится ли текст на листке верным или ложным заключением опре'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model(TopPSampler(p=0.5), 'Top-P')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf6328",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94405403",
   "metadata": {},
   "source": [
    "## 4 Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12465d7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 20px; padding: 15px 0;\">\n",
    "    <a href=\"#Содержание\" data-toc-modified-id=\"Содержание\" style=\"text-decoration: none; color: #296eaa; border: 2px dashed #296eaa; opacity: 0.8; border-radius: 3px; padding: 10px 80px;\">\n",
    "        В начало файла ↑\n",
    "    </a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

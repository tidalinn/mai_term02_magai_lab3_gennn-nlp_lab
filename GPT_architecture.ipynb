{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be80210a",
   "metadata": {},
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<br>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#1-Подготовка-окружения\">\n",
    "                    <span class=\"toc-item-num\">1&nbsp;&nbsp;</span>\n",
    "                    Подготовка окружения\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#2-Загрузка-данных\">\n",
    "                    <span class=\"toc-item-num\">2&nbsp;&nbsp;</span>\n",
    "                    Загрузка данных\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#3-Трансформерная-архитектура-GPT\">\n",
    "                    <span class=\"toc-item-num\">3&nbsp;&nbsp;</span>\n",
    "                    Трансформерная архитектура GPT\n",
    "                </a>\n",
    "            </span>\n",
    "            <ul class=\"toc-item\">\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#3.1-Токенизация-символов\">\n",
    "                            <span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>\n",
    "                            Токенизация символов\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#3.2-Подготовка-модели\">\n",
    "                            <span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>\n",
    "                            Подготовка модели\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#3.3-Обучение-модели\">\n",
    "                            <span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>\n",
    "                            Обучение модели\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "                <li>\n",
    "                    <span>\n",
    "                        <a href=\"#3.4-Генерация-текста\">\n",
    "                            <span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>\n",
    "                            Генерация текста\n",
    "                        </a>\n",
    "                    </span>\n",
    "                </li>\n",
    "            </ul>\n",
    "        </li>\n",
    "        <li>\n",
    "            <span>\n",
    "                <a href=\"#4-Общий-вывод\">\n",
    "                    <span class=\"toc-item-num\">4&nbsp;&nbsp;</span>\n",
    "                    Общий вывод\n",
    "                </a>\n",
    "            </span>\n",
    "        </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d4a79",
   "metadata": {},
   "source": [
    "# Генеративные текстовые нейросети | Архитектура GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef168b4",
   "metadata": {},
   "source": [
    "**Постановка задачи:** натренировать и сравнить качество нескольких генеративных текстовых моделей на одном из заданных текстовых датасетов.\n",
    "\n",
    "**Источник данных:** [Harry Potter and the Methods of Rationality](https://hpmor.ru/).\n",
    "\n",
    "**Характер данных:** текст книги \"Гарри Поттер и методы рационального мышления\".\n",
    "\n",
    "**Основные этапы:** исследовать следующие нейросетевые архитектуры:\n",
    "\n",
    "1. Simple RNN с посимвольной и пословной токенизацией.\n",
    "2. Однонаправленная однослойная и многослойная LSTM c посимвольной токенизацией и токенизацией по словам и [на основе BPE](https://keras.io/api/keras_nlp/tokenizers/byte_pair_tokenizer/).\n",
    "3. Двунаправленная LSTM.\n",
    "4. *(На хорошую оценку)* трансформерная архитектура (GPT) \"с нуля\" [пример](https://keras.io/examples/generative/text_generation_gpt/).\n",
    "5. *(На отличную оценку)* дообучение предобученной GPT-сети [пример](https://github.com/ZotovaElena/RuGPT3_finetuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f3ad7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f310f623",
   "metadata": {},
   "source": [
    "# Реализации\n",
    "\n",
    "1. [RNN с посимвольной токенизацией](RNN_char.ipynb)\n",
    "2. [RNN с пословной токенизацией](RNN_word.ipynb)\n",
    "3. [Однонаправленная LSTM + BPE](LSTM_unidirectional_BPE.ipynb)\n",
    "4. [Двунаправленная LSTM](LSTM_bidirectional.ipynb)\n",
    "5. Архитектура GPT (текущий файл)\n",
    "6. [Дообучение GPT](GPT_finetuning.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a6f19",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec375e8c",
   "metadata": {},
   "source": [
    "## 1 Подготовка окружения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c943c00",
   "metadata": {},
   "source": [
    "Импорт библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13be500e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.data import TextLineDataset, AUTOTUNE\n",
    "from keras import callbacks, utils, losses\n",
    "\n",
    "import keras.layers as l\n",
    "\n",
    "import keras_nlp\n",
    "\n",
    "from keras_nlp import tokenizers, samplers, metrics\n",
    "\n",
    "# custom funcs\n",
    "import utils.web_scrapping as web\n",
    "import utils.process_checking as check\n",
    "import utils.data_preprocessing as data_prep\n",
    "import utils.charts_plotting as chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0125df91",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c9f4d",
   "metadata": {},
   "source": [
    "## 2 Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a64788",
   "metadata": {},
   "source": [
    "Формирование/загрузка набора данных в зависимости от его наличия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c940d6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded from data/hpmor.txt\n"
     ]
    }
   ],
   "source": [
    "data = web.load_data('https://hpmor.ru/', 'hpmor.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f00925",
   "metadata": {},
   "source": [
    "Выведение на экран начала текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac6ca3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'гарри поттер и методы рационального мышления. элиезер юдковский (less wrong). петуния вышла замуж не за дурсля, а за университетского профессора, и гарри попал в гораздо более благоприятную среду. у него были частные учителя, дискуссии с отцом, а главное — книги, сотни и тысячи научных и фантастических книг. в 11 лет гарри знаком с квантовой механикой, когнитивной психологией, теорией вероятностей и другими вещами. но гарри не просто вундеркинд, у него есть загадочная тёмная сторона, которая явн'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42e367a",
   "metadata": {},
   "source": [
    "Выведение на экран общего числа слов и предложений в тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcb836ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего слов: 559791\n",
      "Всего предложений: 37351\n"
     ]
    }
   ],
   "source": [
    "check.print_total(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aab65d",
   "metadata": {},
   "source": [
    "Задание путей до выборок данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146037df",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = 'data/hpmor_train.txt'\n",
    "path_valid = 'data/hpmor_valid.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d0b5d5",
   "metadata": {},
   "source": [
    "Формирование тренировочной и валидационной выборок:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0cb02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already exist\n"
     ]
    }
   ],
   "source": [
    "data_prep.train_valid_test_split_save(data, path_train, path_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b88fc",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85df30",
   "metadata": {},
   "source": [
    "## 3 Трансформерная архитектура GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01e36c3",
   "metadata": {},
   "source": [
    "### 3.1 Токенизация символов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c486be",
   "metadata": {},
   "source": [
    "Задание функции разделения данных на признаки и целевой признак:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "830176b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inputs: TextLineDataset):\n",
    "    outputs = tokenizer(inputs)\n",
    "    features = start_packer(outputs)\n",
    "    labels = outputs\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79fef3e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f759ae5",
   "metadata": {},
   "source": [
    "Выведение на экран максимальной и минимальной длины предложений в тексте:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d61c301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная длина строки: 217\n",
      "Минимальная длина строки: 0\n"
     ]
    }
   ],
   "source": [
    "check.print_max_min_len(data.split('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56b30f8",
   "metadata": {},
   "source": [
    "Задание констант:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e43208",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SEQ_LEN = 128\n",
    "MIN_SEQ_LEN = 450\n",
    "MAX_VOCAB_LEN = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57702265",
   "metadata": {},
   "source": [
    "Формирование датасетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c6903ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    TextLineDataset(path_train)\n",
    "    .filter(lambda x: tf.strings.length(x) > MIN_SEQ_LEN)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .shuffle(buffer_size=256)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    TextLineDataset(path_valid)\n",
    "    .filter(lambda x: tf.strings.length(x) > MIN_SEQ_LEN)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3143c30c",
   "metadata": {},
   "source": [
    "Выведение на экран первого бартча тренировочного датасета:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40fe9032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'профессор макгонагалл, у которой использование маховика времени не вошло в привычку настолько, как у директора и гарри, после окончания совещания сразу же ушла спать звук шёл секунд двадцать, поэтому, наверное, минуты две на метле… движением настолько гладким, что оно казалось неосознанным, профессор макгонагалл приняла нужную позу: — экспекто патронум сгусток красного света почти в упор ударил в затылок не-сьюзен и швырнул её на пол — с ним всё в порядке, ему лишь нужен день отдыха — ты должен '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(train_dataset.as_numpy_iterator())[0][0].decode('utf-8')[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da99bc9",
   "metadata": {},
   "source": [
    "Формирование словаря:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15498b0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary = tokenizers.compute_word_piece_vocabulary(\n",
    "    train_dataset,\n",
    "    vocabulary_size=MAX_VOCAB_LEN,\n",
    "    lowercase=True,\n",
    "    reserved_tokens=['[PAD]', '[UNK]', '[BOS]'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce148578",
   "metadata": {},
   "source": [
    "Выведение на экран общего числа слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91563ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Слов в словаре:', len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069b3e39",
   "metadata": {},
   "source": [
    "Выведение на экран первых элементов словаря:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bda0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b697ac0",
   "metadata": {},
   "source": [
    "Формирование словаря токенов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizers.WordPieceTokenizer(\n",
    "    vocabulary=vocabulary,\n",
    "    sequence_length=SEQ_LEN,\n",
    "    lowercase=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e8aae6",
   "metadata": {},
   "source": [
    "задание объекта, формирующего токен начала строки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2893b4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_packer = keras_nlp.layers.StartEndPacker(\n",
    "    sequence_length=SEQ_LEN,\n",
    "    start_value=tokenizer.token_to_id('[BOS]'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257401f",
   "metadata": {},
   "source": [
    "Токенизация датасетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_dataset.map(preprocess, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
    "valid = valid_dataset.map(preprocess, num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d572d6",
   "metadata": {},
   "source": [
    "Выведение на экран экземпляра признаков и целевого признака:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a226a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "check.print_single_element(\n",
    "    train.get_single_element()[0],\n",
    "    train.get_single_element()[1],\n",
    "    tokenizer.id_to_token\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53456cbc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e46b7",
   "metadata": {},
   "source": [
    "### 3.2 Подготовка модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8241077",
   "metadata": {},
   "source": [
    "Задание функции, конструирующей модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e059d4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_construction(vocab_size: int,\n",
    "                       seq_len: int,\n",
    "                       embed_dim: int,\n",
    "                       n_layers: int,\n",
    "                       n_heads: int,\n",
    "                       inter_dim: int) -> keras.Model:\n",
    "    \n",
    "    features = l.Input(shape=(None,), dtype=tf.int32)\n",
    "    \n",
    "    embedding_layer = keras_nlp.layers.TokenAndPositionEmbedding(\n",
    "        vocabulary_size=vocab_size,\n",
    "        sequence_length=seq_len,\n",
    "        embedding_dim=embed_dim,\n",
    "        mask_zero=True,\n",
    "    )\n",
    "    \n",
    "    x = embedding_layer(features)\n",
    "    \n",
    "    for _ in range(n_layers):\n",
    "        decoder_layer = keras_nlp.layers.TransformerDecoder(\n",
    "            num_heads=n_heads,\n",
    "            intermediate_dim=inter_dim,\n",
    "        )\n",
    "        x = decoder_layer(x)\n",
    "        \n",
    "    target = l.Dense(vocab_size)(x)\n",
    "    \n",
    "    model = keras.Model(inputs=features, outputs=target)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fecb4d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6e73c",
   "metadata": {},
   "source": [
    "Задание модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3309d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_construction(\n",
    "    vocab_size=MAX_VOCAB_LEN,\n",
    "    seq_len=SEQ_LEN,\n",
    "    embed_dim=256,\n",
    "    n_layers=2,\n",
    "    n_heads=3,\n",
    "    inter_dim=256    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ee3bd",
   "metadata": {},
   "source": [
    "Выведение на экран таблицы поведения параметров на слоях нейросети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc11006",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37682b51",
   "metadata": {},
   "source": [
    "Проверка наличия папки для хранения изображений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736437f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('images/') == False:\n",
    "    os.mkdir('images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a949d3f2",
   "metadata": {},
   "source": [
    "Выведение на экран отображения послойной обработки данных моделью:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25fcbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, 'images/gpt_arch.png', show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4259dd83",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae59a809",
   "metadata": {},
   "source": [
    "### 3.3 Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d352c",
   "metadata": {},
   "source": [
    "Проверка наличия папки для хранения контрольных точек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd12e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir('checkpoints/') == False:\n",
    "    os.mkdir('checkpoints/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2329cf30",
   "metadata": {},
   "source": [
    "Задание пути для хранения контрольных точек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8390ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoints = 'checkpoints/gpt_arch'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb522f9",
   "metadata": {},
   "source": [
    "Проверка наличия папки для хранения контрольных точек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa414b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(path_checkpoints) == False:\n",
    "    os.mkdir(path_checkpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c3548",
   "metadata": {},
   "source": [
    "Задание коллбека точек сохранения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823a826",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(path_checkpoints, 'checkpoint_{epoch}')\n",
    "\n",
    "checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    save_weights_only=True, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a361ae",
   "metadata": {},
   "source": [
    "Подготовка модели к обучению:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39910720",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam', \n",
    "    loss=losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a8d04d",
   "metadata": {},
   "source": [
    "Обучение модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588777e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train, \n",
    "    validation_data=valid, \n",
    "    epochs=200, \n",
    "    verbose=2,\n",
    "    callbacks=[checkpoint_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d3bb6a",
   "metadata": {},
   "source": [
    "Выведение на экран графика значений функции потерь и качества модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a47a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chart.plot_loss_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16eba7a",
   "metadata": {},
   "source": [
    "Сброс состояния модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2579ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a02caa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba39d1",
   "metadata": {},
   "source": [
    "### 3.4 Генерация текста"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4db7d9",
   "metadata": {},
   "source": [
    "Задание функции, заполняющей тело запроса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2dbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next(prompt: tf.Tensor, cache: tf.Tensor, index: tf.Tensor) -> Tuple[tf.Tensor, None, Tuple]:\n",
    "    logits = model(prompt)[:, index - 1, :]\n",
    "    hidden_states = None\n",
    "    return logits, hidden_states, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253f478a",
   "metadata": {},
   "source": [
    "Задание функции предсказания следующего символа:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc778bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(sampler: keras_nlp.samplers) -> str:\n",
    "    prompt = start_packer(tokenizer(['']))\n",
    "    \n",
    "    tokens = sampler(\n",
    "        next=next,\n",
    "        prompt=prompt,\n",
    "        index=1,\n",
    "    )\n",
    "    \n",
    "    text = tokenizer.detokenize(tokens)\n",
    "    return text.numpy()[0].decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d727d5ea",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e724a8",
   "metadata": {},
   "source": [
    "**Greedy search** - алгоритм подбора наиболее вероятного токена на каждом шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33948f42",
   "metadata": {},
   "source": [
    "Генерация текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9592fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(samplers.GreedySampler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe5d9f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220369bc",
   "metadata": {},
   "source": [
    "**Beam search** - алгоритм подбора наиболее вероятной последовательности на каждом шаге и лучшего токена среди всех последовательностей. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afd88da",
   "metadata": {},
   "source": [
    "Генерация текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(samplers.BeamSampler(num_beams=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e7528",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e83ec",
   "metadata": {},
   "source": [
    "**Random search** - алгоритм подбора следующего наиболее вероятного токена, которым может оказаться любое слово из всего корпуса текста, на каждом шаге."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f249cc6",
   "metadata": {},
   "source": [
    "Генерация текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ef0a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(samplers.RandomSampler())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b0e6b4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f2011",
   "metadata": {},
   "source": [
    "**Top-K search** - алгоритм подбора следующего токена по вероятностному распределению, которое распределеяется между фиксированного числа топ-К наиболее вероятных токенов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57bae24",
   "metadata": {},
   "source": [
    "Генерация текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(samplers.TopKSampler(k=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ae8318",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983ecbc5",
   "metadata": {},
   "source": [
    "**Top-P search** - алгоритм подбора следующего токена по вероятностному распределению, неравномерно распределённому среди наиболее вероятных токенов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f023b99",
   "metadata": {},
   "source": [
    "Генерация текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2514b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text(samplers.TopPSampler(p=0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcf6328",
   "metadata": {},
   "source": [
    "<div style=\"background-color: blue; height: 2px; margin: 10px 0;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94405403",
   "metadata": {},
   "source": [
    "## 4 Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f76149",
   "metadata": {},
   "source": [
    "Были продемонстрированы результаты обучения построенной модели с применением различных алгоритмов поиска лучших токенов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12465d7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size: 20px; padding: 15px 0;\">\n",
    "    <a href=\"#Содержание\" data-toc-modified-id=\"Содержание\" style=\"text-decoration: none; color: #296eaa; border: 2px dashed #296eaa; opacity: 0.8; border-radius: 3px; padding: 10px 80px;\">\n",
    "        В начало файла ↑\n",
    "    </a>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
